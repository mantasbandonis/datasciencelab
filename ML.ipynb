{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import operator\n",
    "import time\n",
    "import datetime\n",
    "import platform\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeText(text, path, mode = 'w'):\n",
    "    with open (path, mode, encoding = 'utf-8') as textout:\n",
    "        textout.write((text))\n",
    "        \n",
    "def writeJson(json, path, mode = 'w'):\n",
    "    with open(path, mode) as file:\n",
    "        file.write(json.dumps(json))\n",
    "        \n",
    "def writeCsv(listOut, outputFile):\n",
    "    with open (outputFile, \"w\", newline='', encoding = 'utf-8') as outputfile:\n",
    "        writer = csv.writer(outputfile, delimiter = \",\")\n",
    "        for element in listOut:\n",
    "            writer.writerow(element)\n",
    "            \n",
    "def getTxt(path):\n",
    "    return open(path, 'r').read()\n",
    "\n",
    "def getCsv(path, delim = ','):\n",
    "    list_return = []\n",
    "    with open (path, encoding = 'utf-8') as file:\n",
    "        csvreader = csv.reader(file, delimiter = delim)        \n",
    "        for i, line in enumerate(csvreader):\n",
    "            list_return.append(line)\n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFloatCsv(path, delim = ','):\n",
    "    list_return = []\n",
    "    with open (path, encoding = 'utf-8') as file:\n",
    "        csvreader = csv.reader(file, delimiter = delim)        \n",
    "        for i, line in enumerate(csvreader):\n",
    "            list_return.append([float(x) for x in line])\n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    feat = getFloatCsv('..\\\\output\\\\feat.csv')\n",
    "else:\n",
    "    feat = getFloatCsv('../output/feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    label = getCsv('..\\\\output\\\\labels.csv')\n",
    "else:\n",
    "    label = getCsv('../output/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll = []\n",
    "# for line in label:\n",
    "#     for word in line:\n",
    "#         if word not in ll:\n",
    "#             ll.append(word)\n",
    "# len(ll)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(label)\n",
    "y = multilabel_binarizer.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.40620422,  0.37869263,  0.58084106, ...,  0.03137207,\n",
       "          0.64916992, -1.32333374],\n",
       "        [-0.50666809,  0.45892334,  0.73953247, ..., -0.08215332,\n",
       "          1.0402832 , -1.47055054],\n",
       "        [-0.44416809,  0.43939209,  0.61599731, ..., -0.01086426,\n",
       "          0.69067383, -1.39877319],\n",
       "        ...,\n",
       "        [ 2.33901978,  7.3309021 , -1.46138   , ..., -2.83006287,\n",
       "          7.28421021,  1.01919556],\n",
       "        [-1.52600098,  1.57382202,  2.0201416 , ..., -1.18414307,\n",
       "          1.93450928, -0.99139404],\n",
       "        [-1.51477051,  1.66415405,  1.97241211, ..., -1.46881104,\n",
       "          2.1239624 , -1.10540771]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dims training set:  (2694, 300) (2694, 125)\n",
      "Dims training set:  (674, 300) (674, 125)\n"
     ]
    }
   ],
   "source": [
    "print('Dims training set: ', train_X.shape, train_y.shape)\n",
    "print('Dims training set: ', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating own Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMLA(test_y, pred_labels):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, labelset in enumerate(test_y):\n",
    "        for j, label in enumerate(labelset):\n",
    "            if (label == 1) & (pred_labels[i][j] == 1):\n",
    "                tp += 1\n",
    "            if (label == 0) & (pred_labels[i][j] == 1):\n",
    "                fp += 1\n",
    "            if (label == 0) & (pred_labels[i][j] == 0):\n",
    "                tn += 1\n",
    "            if (label == 1) & (pred_labels[i][j] == 0):\n",
    "                fn += 1\n",
    "#     print(tp, fp)\n",
    "#     print(fn, tn)\n",
    "\n",
    "    mall = (fp + tp)/(tp+fp+tn+fn)\n",
    "    mp = tp/(tp+fp)\n",
    "    return ((mall**(1/9) + mp**(1/9))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridResultRFC(data, n_est1, n_est2, n_est_grid, depth1, depth2, depth_grid, param_3, param3_1_2, param3_grid, filename = 'log_rf_grid', thread = 1):\n",
    "    train_X, test_X, train_y, test_y = data[0], data[1], data[2], data[3]\n",
    "    acc_best = 0\n",
    "    prec_best = 0\n",
    "    mla_best = 0\n",
    "    acc_params_best = [0,0,0]\n",
    "    prec_params_best = [0,0,0]\n",
    "    mla_params_best = [0,0,0]\n",
    "    str_log = 'Started at:\\n' + datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S') + '\\nThread: ' + str(thread) + '\\n'\n",
    "    print(str_log)\n",
    "    est_runs = (n_est2-n_est1)/n_est_grid\n",
    "    depth_runs = (depth2-depth1)/depth_grid\n",
    "    param3_runs = (param3_1_2-param_3)/param3_grid\n",
    "    str_tmp = 'Grid Search will test ' + str(est_runs*depth_runs*param3_runs) + ' combinations.\\n'\n",
    "    str_log += str_tmp\n",
    "    print(str_tmp)\n",
    "    \n",
    "    est_act = n_est1\n",
    "    depth_act = depth1\n",
    "    param3_act = param_3\n",
    "    \n",
    "    while (est_act < n_est2):\n",
    "        depth_act = depth1\n",
    "        while (depth_act < depth2):\n",
    "            param3_act = param_3\n",
    "            while (param3_act < param3_1_2):\n",
    "                rf = RandomForestClassifier(n_estimators=est_act, max_depth=depth_act, n_jobs = -1)\n",
    "                rf.fit(train_X, train_y)\n",
    "                pred_rf = rf.predict(test_X)        \n",
    "                prec =  metrics.precision_score(test_y, pred_rf, average=\"samples\")\n",
    "                acc = metrics.accuracy_score(test_y, pred_rf)\n",
    "                mla = getMLA(test_y, pred_rf)\n",
    "                print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                str_tmp = '----------------------\\n'+ 'Thread: ' + str(thread) + '\\n' + 'Params: '+str(est_act)+','+str(depth_act)+','+str(param3_act)+'\\n'+'Accuracy: '+str(acc)+';'+' Precision: '+str(prec)+';'+' Own Metric: '+str(mla)+'\\n'\n",
    "                print('Own Metric: ', str(mla_best), '\\nParams: ', str(mla_params_best))\n",
    "                print('Accuracy: ', str(acc_best), '\\nParams: ', str(acc_params_best))\n",
    "                print('Precision: ', str(prec_best), '\\nParams: ', str(prec_params_best), '\\n')\n",
    "                str_log += str_tmp\n",
    "                print(str_tmp)\n",
    "                if acc_best <= acc:\n",
    "                    acc_best = acc\n",
    "                    acc_params_best = [est_act,depth_act,param3_act]\n",
    "                if prec_best <= prec:\n",
    "                    prec_best = prec\n",
    "                    prec_params_best = [est_act,depth_act,param3_act]\n",
    "                if mla_best <= mla:\n",
    "                    mla_best = mla\n",
    "                    mla_params_best = [est_act,depth_act,param3_act]\n",
    "                param3_act += param3_grid\n",
    "            depth_act += depth_grid\n",
    "        est_act += n_est_grid\n",
    "        \n",
    "    str_tmp = '==========================\\n==========================\\n\\n\\n'+'Accuracy: '+str(acc_best)+'\\nParams: '+str(acc_params_best) + '\\n' + 'Precision: '+str(prec_best)+'\\nParams: '+str(prec_params_best)+ 'Own Metric: '+str(mla_best)+'\\nParams: '+str(mla_params_best)+'\\n'+'Ended at:\\n'+datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    str_log += str_tmp\n",
    "    \n",
    "    print('==========================\\n==========================\\n\\n')\n",
    "    print('Thread: ', thread)\n",
    "    print('Own Metric: ', str(mla_best), '\\nParams: ', str(mla_params_best))\n",
    "    print('Accuracy: ', str(acc_best), '\\nParams: ', str(acc_params_best))\n",
    "    print('Precision: ', str(prec_best), '\\nParams: ', str(prec_params_best), '\\n\\n')\n",
    "    print('Ended at:\\n' + datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    writeText(str_log, ('..\\\\output\\\\' + filename + '.txt'))             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_set = [train_X, test_X, train_y, test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "thread_list = []\n",
    "\n",
    "t1 = threading.Thread(target=gridResultRFC, args=(test_train_set, 100, 151, 10, 40, 45, 2, 1, 3, 3, 'log_rf_grid_1.3', 1))\n",
    "t2 = threading.Thread(target=gridResultRFC, args=(test_train_set, 100, 151, 10, 46, 51, 2, 1, 3, 3, 'log_rf_grid_2.3', 2))\n",
    "t3 = threading.Thread(target=gridResultRFC, args=(test_train_set, 100, 151, 10, 52, 57, 2, 1, 3, 3, 'log_rf_grid_3.3', 3))\n",
    "# t4 = threading.Thread(target=gridResultRFC, args=(test_train_set, 175, 226, 25, 40, 45, 2, 1, 3, 3, 'log_rf_grid_4.2', 4))\n",
    "# t5 = threading.Thread(target=gridResultRFC, args=(test_train_set, 175, 226, 25, 46, 51, 2, 1, 3, 3, 'log_rf_grid_5.2', 5))\n",
    "# t6 = threading.Thread(target=gridResultRFC, args=(test_train_set, 175, 226, 25, 52, 57, 2, 1, 3, 3, 'log_rf_grid_6.2', 6))\n",
    "\n",
    "\n",
    "# Sticks the thread in a list so that it remains accessible\n",
    "thread_list.append(t1)\n",
    "thread_list.append(t2)\n",
    "thread_list.append(t3)\n",
    "# thread_list.append(t4)\n",
    "# thread_list.append(t5)\n",
    "# thread_list.append(t6)\n",
    "\n",
    "# for thread in thread_list:\n",
    "#     thread.start()\n",
    "\n",
    "# for thread in thread_list:\n",
    "#     thread.join()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6008902077151336 0.8413786016159903 0.8405466748774202\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=115, max_depth=42, n_jobs = -1)\n",
    "rf.fit(train_X, train_y)\n",
    "pred_rf = rf.predict(test_X)\n",
    "prec =  metrics.precision_score(test_y, pred_rf, average=\"samples\")\n",
    "acc = metrics.accuracy_score(test_y, pred_rf)\n",
    "mla = getMLA(test_y, pred_rf)\n",
    "print(acc, prec, mla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5905044510385756 0.8408699114930569 0.8405806883955813\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=125, max_depth=50, n_jobs = -1)\n",
    "rf2.fit(train_X, train_y)\n",
    "pred_rf2 = rf2.predict(test_X)\n",
    "prec =  metrics.precision_score(test_y, pred_rf2, average=\"samples\")\n",
    "acc = metrics.accuracy_score(test_y, pred_rf2)\n",
    "mla = getMLA(test_y, pred_rf2)\n",
    "print(acc, prec, mla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle\n",
    "# save the classifier\n",
    "with open('dumped_randomforestclassifier.pkl', 'wb') as fid:\n",
    "    _pickle.dump(rf, fid)  \n",
    "with open('dumped_randomforestclassifier2.pkl', 'wb') as fid:\n",
    "    _pickle.dump(rf2, fid)    \n",
    "with open('binarizer.pkl', 'wb') as fid:\n",
    "    _pickle.dump(multilabel_binarizer, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6008902077151336 0.8413786016159903\n"
     ]
    }
   ],
   "source": [
    "# load it again\n",
    "with open('dumped_randomforestclassifier.pkl', 'rb') as fid:\n",
    "    rf_load = _pickle.load(fid)\n",
    "with open('binarizer.pkl', 'rb') as fid:\n",
    "    bin_load = _pickle.load(fid)\n",
    "\n",
    "pred_rf2 = rf_load.predict(test_X)\n",
    "prec =  metrics.precision_score(test_y, pred_rf2, average=\"samples\")\n",
    "acc = metrics.accuracy_score(test_y, pred_rf2)\n",
    "print(acc, prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rf2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt_lb = 0\n",
    "# detrans_pred = bin_load.inverse_transform(pred_rf2[400:430])\n",
    "# detrans_y = bin_load.inverse_transform(test_y[400:430])\n",
    "# while cnt_lb < 30:\n",
    "#     print('Predicted Labels: ', detrans_pred[cnt_lb])\n",
    "#     print('Actual Labels: ', detrans_y[cnt_lb])\n",
    "#     print('==================')\n",
    "#     cnt_lb += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n = 1\n",
    "# n_max =50\n",
    "# l_acc, l_prec = [], []\n",
    "# acc_n_best, prec_n_best, acc_best, prec_best = 0, 0, 0, 0\n",
    "# while n < 50:\n",
    "#     print('Evaluate n=', n)\n",
    "#     knn = KNeighborsClassifier(n_neighbors=n)\n",
    "#     knn.fit(train_X, train_y)\n",
    "    \n",
    "#     pred_knn = knn.predict(test_X)\n",
    "#     prec =  metrics.precision_score(test_y, pred_knn, average=\"samples\")\n",
    "#     acc = metrics.accuracy_score(test_y, pred_knn)\n",
    "    \n",
    "#     l_acc.append(acc)\n",
    "#     l_prec.append(prec)\n",
    "    \n",
    "#     if acc_best <= acc:\n",
    "#         acc_best = acc\n",
    "#         acc_n_best = n\n",
    "#     if prec_best <= prec:\n",
    "#         prec_best = prec\n",
    "#         prec_n_best = n\n",
    "        \n",
    "#     n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# l_prec, l_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_n_best, acc_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prec_n_best, prec_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_knn = knn.predict(test_X)\n",
    "# print('Precision: ', metrics.precision_score(test_y, pred_knn, average=\"samples\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy: ', metrics.accuracy_score(test_y, pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnevsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# ovr = OneVsRestClassifier(RandomForestClassifier(n_estimators=120, max_depth=50, n_jobs=-1))\n",
    "# ovr.fit(train_X, train_y)\n",
    "# ovr_pred = ovr.predict(test_X)\n",
    "\n",
    "# ovr = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=30))\n",
    "# ovr.fit(train_X, train_y)\n",
    "# ovr_pred = ovr.predict(test_X)\n",
    "\n",
    "# metrics.precision_score(test_y, ovr_pred, average=\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridResultOVR_kNN(data, param_3, param3_1_2, param3_grid, filename = 'log_ovrknn_grid', thread = 1):\n",
    "    train_X, test_X, train_y, test_y = data[0], data[1], data[2], data[3]\n",
    "    acc_best = 0\n",
    "    prec_best = 0\n",
    "    mla_best = 0\n",
    "    acc_params_best = 0\n",
    "    prec_params_best = 0\n",
    "    mla_params_best = 0\n",
    "    str_log = 'Started at:\\n' + datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S') + '\\nThread: ' + str(thread) + '\\n'\n",
    "    print(str_log)\n",
    "    param3_runs = (param3_1_2-param_3)/param3_grid\n",
    "    str_tmp = 'Grid Search will test ' + str(param3_runs) + ' combinations.\\n'\n",
    "    str_log += str_tmp\n",
    "    print(str_tmp)\n",
    "\n",
    "    param3_act = param_3\n",
    "    \n",
    "    while (param3_act < param3_1_2):\n",
    "        ovr = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=param3_act))\n",
    "        ovr.fit(train_X, train_y)\n",
    "        pred_ovr = ovr.predict(test_X)        \n",
    "        prec =  metrics.precision_score(test_y, pred_ovr, average=\"samples\")\n",
    "        acc = metrics.accuracy_score(test_y, pred_ovr)\n",
    "        mla = getMLA(test_y, pred_ovr)\n",
    "        print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        str_tmp = '----------------------\\n'+ 'Thread: ' + str(thread) + '\\n' + 'Params: '+str(param3_act)+'\\n'+'Accuracy: '+str(acc)+';'+' Precision: '+str(prec)+';'+' Own Metric: '+str(mla)+'\\n'\n",
    "        print('Own Metric: ', str(mla_best), '\\nParams: ', str(mla_params_best))\n",
    "        print('Accuracy: ', str(acc_best), '\\nParams: ', str(acc_params_best))\n",
    "        print('Precision: ', str(prec_best), '\\nParams: ', str(prec_params_best), '\\n')\n",
    "        str_log += str_tmp\n",
    "        print(str_tmp)\n",
    "        if acc_best <= acc:\n",
    "            acc_best = acc\n",
    "            acc_params_best = param3_act\n",
    "        if prec_best <= prec:\n",
    "            prec_best = prec\n",
    "            prec_params_best = param3_act\n",
    "        if mla_best <= mla:\n",
    "            mla_best = mla                \n",
    "            mla_params_best = [param3_act]\n",
    "        param3_act += param3_grid\n",
    "        \n",
    "    str_tmp = '==========================\\n==========================\\n\\n\\n'+'Accuracy: '+str(acc_best)+'\\nParams: '+str(acc_params_best) + '\\n' + 'Precision: '+str(prec_best)+'\\nParams: '+str(prec_params_best)+'\\n'+'Own Metric: '+str(mla_best)+'\\nParams: '+str(mla_params_best)+'\\n'+'Ended at:\\n'+datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    str_log += str_tmp\n",
    "    \n",
    "    print('==========================\\n==========================\\n\\n')\n",
    "    print('Thread: ', thread)\n",
    "    print('Own Metric: ', str(mla_best), '\\nParams: ', str(mla_params_best))\n",
    "    print('Accuracy: ', str(acc_best), '\\nParams: ', str(acc_params_best))\n",
    "    print('Precision: ', str(prec_best), '\\nParams: ', str(prec_params_best), '\\n\\n')\n",
    "    print('Ended at:\\n' + datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    writeText(str_log, ('..\\\\output\\\\' + filename + '.txt'))             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at:\n",
      "2018-12-05 00:34:15\n",
      "Thread: 1\n",
      "Started at:\n",
      "2018-12-05 00:34:15\n",
      "Thread: 2\n",
      "\n",
      "Grid Search will test 2.2 combinations.\n",
      "\n",
      "\n",
      "Grid Search will test 2.2 combinations.\n",
      "\n",
      "Started at:\n",
      "2018-12-05 00:34:15\n",
      "Thread: 3\n",
      "\n",
      "Grid Search will test 2.2 combinations.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 106 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 106 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 106 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 109 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 109 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 109 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-05 00:36:08\n",
      "Own Metric:  0 \n",
      "Params:  0\n",
      "Accuracy:  0 \n",
      "Params:  0\n",
      "Precision:  0 \n",
      "Params:  0 \n",
      "\n",
      "----------------------\n",
      "Thread: 1\n",
      "Params: 5\n",
      "Accuracy: 0.5178041543026706; Precision: 0.8059846022754034; Own Metric: 0.83953403547044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 106 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 109 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-05 00:36:52\n",
      "Own Metric:  0 \n",
      "Params:  0\n",
      "Accuracy:  0 \n",
      "Params:  0\n",
      "Precision:  0 \n",
      "Params:  0 \n",
      "\n",
      "----------------------\n",
      "Thread: 2\n",
      "Params: 20\n",
      "Accuracy: 0.27596439169139464; Precision: 0.6698581833596671; Own Metric: 0.8329807132716607\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 106 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 109 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-05 00:37:00\n",
      "Own Metric:  0 \n",
      "Params:  0\n",
      "Accuracy:  0 \n",
      "Params:  0\n",
      "Precision:  0 \n",
      "Params:  0 \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 35\n",
      "Accuracy: 0.21513353115727002; Precision: 0.6356487725923928; Own Metric: 0.8300977405906169\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 106 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 109 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-05 00:38:26\n",
      "Own Metric:  0.83953403547044 \n",
      "Params:  [5]\n",
      "Accuracy:  0.5178041543026706 \n",
      "Params:  5\n",
      "Precision:  0.8059846022754034 \n",
      "Params:  5 \n",
      "\n",
      "----------------------\n",
      "Thread: 1\n",
      "Params: 10\n",
      "Accuracy: 0.413946587537092; Precision: 0.7358077382558094; Own Metric: 0.8362038844359568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 106 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 109 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-05 00:39:26\n",
      "Own Metric:  0.8329807132716607 \n",
      "Params:  [20]\n",
      "Accuracy:  0.27596439169139464 \n",
      "Params:  20\n",
      "Precision:  0.6698581833596671 \n",
      "Params:  20 \n",
      "\n",
      "----------------------\n",
      "Thread: 2\n",
      "Params: 25\n",
      "Accuracy: 0.258160237388724; Precision: 0.6555424422264184; Own Metric: 0.832056642076885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 106 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 109 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-05 00:39:42\n",
      "Own Metric:  0.8300977405906169 \n",
      "Params:  [35]\n",
      "Accuracy:  0.21513353115727002 \n",
      "Params:  35\n",
      "Precision:  0.6356487725923928 \n",
      "Params:  35 \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 40\n",
      "Accuracy: 0.19881305637982197; Precision: 0.6151669300037252; Own Metric: 0.8290222054092249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 106 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 109 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-05 00:40:51\n",
      "Own Metric:  0.83953403547044 \n",
      "Params:  [5]\n",
      "Accuracy:  0.5178041543026706 \n",
      "Params:  5\n",
      "Precision:  0.8059846022754034 \n",
      "Params:  5 \n",
      "\n",
      "----------------------\n",
      "Thread: 1\n",
      "Params: 15\n",
      "Accuracy: 0.3486646884272997; Precision: 0.7077873906508921; Own Metric: 0.8350298240082841\n",
      "\n",
      "==========================\n",
      "==========================\n",
      "\n",
      "\n",
      "Thread:  1\n",
      "Own Metric:  0.83953403547044 \n",
      "Params:  [5]\n",
      "Accuracy:  0.5178041543026706 \n",
      "Params:  5\n",
      "Precision:  0.8059846022754034 \n",
      "Params:  5 \n",
      "\n",
      "\n",
      "Ended at:\n",
      "2018-12-05 00:40:51\n",
      "2018-12-05 00:41:54\n",
      "Own Metric:  0.8329807132716607 \n",
      "Params:  [20]\n",
      "Accuracy:  0.27596439169139464 \n",
      "Params:  20\n",
      "Precision:  0.6698581833596671 \n",
      "Params:  20 \n",
      "\n",
      "----------------------\n",
      "Thread: 2\n",
      "Params: 30\n",
      "Accuracy: 0.22106824925816024; Precision: 0.633400291597621; Own Metric: 0.8305723227031581\n",
      "\n",
      "==========================\n",
      "==========================\n",
      "\n",
      "\n",
      "Thread:  2\n",
      "Own Metric:  0.8329807132716607 \n",
      "Params:  [20]\n",
      "Accuracy:  0.27596439169139464 \n",
      "Params:  20\n",
      "Precision:  0.6698581833596671 \n",
      "Params:  20 \n",
      "\n",
      "\n",
      "Ended at:\n",
      "2018-12-05 00:41:54\n",
      "2018-12-05 00:42:11\n",
      "Own Metric:  0.8300977405906169 \n",
      "Params:  [35]\n",
      "Accuracy:  0.21513353115727002 \n",
      "Params:  35\n",
      "Precision:  0.6356487725923928 \n",
      "Params:  35 \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 45\n",
      "Accuracy: 0.1943620178041543; Precision: 0.6057950210027362; Own Metric: 0.8289018222947322\n",
      "\n",
      "==========================\n",
      "==========================\n",
      "\n",
      "\n",
      "Thread:  3\n",
      "Own Metric:  0.8300977405906169 \n",
      "Params:  [35]\n",
      "Accuracy:  0.21513353115727002 \n",
      "Params:  35\n",
      "Precision:  0.6356487725923928 \n",
      "Params:  35 \n",
      "\n",
      "\n",
      "Ended at:\n",
      "2018-12-05 00:42:11\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "thread_list = []\n",
    "\n",
    "t1 = threading.Thread(target=gridResultOVR_kNN, args=(test_train_set, 5, 16, 5, 'log_ovrknn_grid_1', 1))\n",
    "t2 = threading.Thread(target=gridResultOVR_kNN, args=(test_train_set, 20, 31, 5, 'log_ovrknn_grid_2', 2))\n",
    "t3 = threading.Thread(target=gridResultOVR_kNN, args=(test_train_set, 35, 46, 5, 'log_ovrknn_grid_3', 3))\n",
    "\n",
    "# Sticks the thread in a list so that it remains accessible\n",
    "thread_list.append(t1)\n",
    "thread_list.append(t2)\n",
    "thread_list.append(t3)\n",
    "\n",
    "# for thread in thread_list:\n",
    "#     thread.start()\n",
    "\n",
    "# for thread in thread_list:\n",
    "#     thread.join()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27596439169139464 0.6698581833596671 0.8329807132716607\n"
     ]
    }
   ],
   "source": [
    "ovrknn = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=20))\n",
    "ovrknn.fit(train_X, train_y)\n",
    "pred_ovrknn = ovrknn.predict(test_X)\n",
    "prec =  metrics.precision_score(test_y, pred_ovrknn, average=\"samples\")\n",
    "acc = metrics.accuracy_score(test_y, pred_ovrknn)\n",
    "mla = getMLA(test_y, pred_ovrknn)\n",
    "print(acc, prec, mla)\n",
    "\n",
    "with open('dumped_ovrknn.pkl', 'wb') as fid:\n",
    "    _pickle.dump(ovrknn, fid)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridResultOVR_RFC(data, n_est1, n_est2, n_est_grid, depth1, depth2, depth_grid, param_3, param3_1_2, param3_grid, filename = 'log_ovrrfc_grid', thread = 1):\n",
    "    train_X, test_X, train_y, test_y = data[0], data[1], data[2], data[3]\n",
    "    acc_best = 0\n",
    "    prec_best = 0\n",
    "    mla_best = 0\n",
    "    acc_params_best = [0,0,0]\n",
    "    prec_params_best = [0,0,0]\n",
    "    mla_params_best = [0,0,0]\n",
    "    str_log = 'Started at:\\n' + datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S') + '\\nThread: ' + str(thread) + '\\n'\n",
    "    print(str_log)\n",
    "    est_runs = (n_est2-n_est1)/n_est_grid\n",
    "    depth_runs = (depth2-depth1)/depth_grid\n",
    "    param3_runs = (param3_1_2-param_3)/param3_grid\n",
    "    str_tmp = 'Grid Search will test ' + str(est_runs*depth_runs*param3_runs) + ' combinations.\\n'\n",
    "    str_log += str_tmp\n",
    "    print(str_tmp)\n",
    "    \n",
    "    est_act = n_est1\n",
    "    depth_act = depth1\n",
    "    param3_act = param_3\n",
    "    \n",
    "    while (est_act < n_est2):\n",
    "        depth_act = depth1\n",
    "        while (depth_act < depth2):\n",
    "            param3_act = param_3\n",
    "            while (param3_act < param3_1_2):\n",
    "                ovr = OneVsRestClassifier(RandomForestClassifier(n_estimators=est_act, max_depth=depth_act, n_jobs = -1))\n",
    "                ovr.fit(train_X, train_y)\n",
    "                pred_ovr = ovr.predict(test_X)        \n",
    "                prec =  metrics.precision_score(test_y, pred_ovr, average=\"samples\")\n",
    "                acc = metrics.accuracy_score(test_y, pred_ovr)\n",
    "                mla = getMLA(test_y, pred_ovr)\n",
    "                print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                str_tmp = '----------------------\\n'+ 'Thread: ' + str(thread) + '\\n' + 'Params: '+str(est_act)+','+str(depth_act)+','+str(param3_act)+'\\n'+'Accuracy: '+str(acc)+';'+' Precision: '+str(prec)+';'+' Own Metric: '+str(mla)+'\\n'\n",
    "                print('Own Metric: ', str(mla_best), '\\nParams: ', str(mla_params_best))\n",
    "                print('Accuracy: ', str(acc_best), '\\nParams: ', str(acc_params_best))\n",
    "                print('Precision: ', str(prec_best), '\\nParams: ', str(prec_params_best), '\\n')\n",
    "                str_log += str_tmp\n",
    "                print(str_tmp)\n",
    "                if acc_best <= acc:\n",
    "                    acc_best = acc\n",
    "                    acc_params_best = [est_act,depth_act,param3_act]\n",
    "                if prec_best <= prec:\n",
    "                    prec_best = prec\n",
    "                    prec_params_best = [est_act,depth_act,param3_act]\n",
    "                if mla_best <= mla:\n",
    "                    mla_best = mla\n",
    "                    mla_params_best = [est_act,depth_act,param3_act]\n",
    "                param3_act += param3_grid\n",
    "            depth_act += depth_grid\n",
    "        est_act += n_est_grid\n",
    "        \n",
    "    str_tmp = '==========================\\n==========================\\n\\n\\n'+'Accuracy: '+str(acc_best)+'\\nParams: '+str(acc_params_best) + '\\n' + 'Precision: '+str(prec_best)+'\\nParams: '+str(prec_params_best)+'Own Metric: '+str(mla_best)+'\\nParams: '+str(mla_params_best)+'\\n'+'Ended at:\\n'+datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    str_log += str_tmp\n",
    "    \n",
    "    print('==========================\\n==========================\\n\\n')\n",
    "    print('Thread: ', thread)\n",
    "    print('Own Metric: ', str(mla_best), '\\nParams: ', str(mla_params_best))\n",
    "    print('Accuracy: ', str(acc_best), '\\nParams: ', str(acc_params_best))\n",
    "    print('Precision: ', str(prec_best), '\\nParams: ', str(prec_params_best), '\\n\\n')\n",
    "    print('Ended at:\\n' + datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    writeText(str_log, ('..\\\\output\\\\' + filename + '.txt'))             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at:\n",
      "2018-12-05 01:26:49\n",
      "Thread: 1\n",
      "Started at:\n",
      "2018-12-05 01:26:49\n",
      "Thread: 2\n",
      "\n",
      "Grid Search will test 3.3999999999999995 combinations.\n",
      "\n",
      "\n",
      "Grid Search will test 3.3999999999999995 combinations.\n",
      "\n",
      "Started at:\n",
      "2018-12-05 01:26:49\n",
      "Thread: 3\n",
      "\n",
      "Grid Search will test 3.3999999999999995 combinations.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-18-0c6ac8e2e054>\", line 28, in gridResultOVR_RFC\n",
      "    ovr.fit(train_X, train_y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\", line 215, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\", line 80, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 316, in fit\n",
      "    random_state=random_state)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\", line 130, in _make_estimator\n",
      "    _set_random_states(estimator, random_state)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\", line 57, in _set_random_states\n",
      "    estimator.set_params(**to_set)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 265, in set_params\n",
      "    valid_params = self.get_params(deep=True)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 241, in get_params\n",
      "    warnings.filters.pop(0)\n",
      "IndexError: pop from empty list\n",
      "\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-18-0c6ac8e2e054>\", line 28, in gridResultOVR_RFC\n",
      "    ovr.fit(train_X, train_y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\", line 215, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\", line 80, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 316, in fit\n",
      "    random_state=random_state)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\", line 130, in _make_estimator\n",
      "    _set_random_states(estimator, random_state)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\", line 57, in _set_random_states\n",
      "    estimator.set_params(**to_set)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 265, in set_params\n",
      "    valid_params = self.get_params(deep=True)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 241, in get_params\n",
      "    warnings.filters.pop(0)\n",
      "IndexError: pop from empty list\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-05 01:29:19\n",
      "Own Metric:  0 \n",
      "Params:  [0, 0, 0]\n",
      "Accuracy:  0 \n",
      "Params:  [0, 0, 0]\n",
      "Precision:  0 \n",
      "Params:  [0, 0, 0] \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 100,52,1\n",
      "Accuracy: 0.5534124629080118; Precision: 0.8368522921193545; Own Metric: 0.8399656168281626\n",
      "\n",
      "2018-12-05 01:30:36\n",
      "Own Metric:  0.8399656168281626 \n",
      "Params:  [100, 52, 1]\n",
      "Accuracy:  0.5534124629080118 \n",
      "Params:  [100, 52, 1]\n",
      "Precision:  0.8368522921193545 \n",
      "Params:  [100, 52, 1] \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 100,54,1\n",
      "Accuracy: 0.56973293768546; Precision: 0.8372031035235783; Own Metric: 0.8398930845586363\n",
      "\n",
      "2018-12-05 01:31:56\n",
      "Own Metric:  0.8399656168281626 \n",
      "Params:  [100, 52, 1]\n",
      "Accuracy:  0.56973293768546 \n",
      "Params:  [100, 54, 1]\n",
      "Precision:  0.8372031035235783 \n",
      "Params:  [100, 54, 1] \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 100,56,1\n",
      "Accuracy: 0.5637982195845698; Precision: 0.8311094197592713; Own Metric: 0.839998000918867\n",
      "\n",
      "2018-12-05 01:33:22\n",
      "Own Metric:  0.839998000918867 \n",
      "Params:  [100, 56, 1]\n",
      "Accuracy:  0.56973293768546 \n",
      "Params:  [100, 54, 1]\n",
      "Precision:  0.8372031035235783 \n",
      "Params:  [100, 54, 1] \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 125,52,1\n",
      "Accuracy: 0.5637982195845698; Precision: 0.8374457639294434; Own Metric: 0.8400333391935793\n",
      "\n",
      "2018-12-05 01:34:49\n",
      "Own Metric:  0.8400333391935793 \n",
      "Params:  [125, 52, 1]\n",
      "Accuracy:  0.56973293768546 \n",
      "Params:  [100, 54, 1]\n",
      "Precision:  0.8374457639294434 \n",
      "Params:  [125, 52, 1] \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 125,54,1\n",
      "Accuracy: 0.5608308605341247; Precision: 0.8285200457307282; Own Metric: 0.839890080143721\n",
      "\n",
      "2018-12-05 01:36:14\n",
      "Own Metric:  0.8400333391935793 \n",
      "Params:  [125, 52, 1]\n",
      "Accuracy:  0.56973293768546 \n",
      "Params:  [100, 54, 1]\n",
      "Precision:  0.8374457639294434 \n",
      "Params:  [125, 52, 1] \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 125,56,1\n",
      "Accuracy: 0.5667655786350149; Precision: 0.8410065947899775; Own Metric: 0.8400252471090522\n",
      "\n",
      "2018-12-05 01:37:52\n",
      "Own Metric:  0.8400333391935793 \n",
      "Params:  [125, 52, 1]\n",
      "Accuracy:  0.56973293768546 \n",
      "Params:  [100, 54, 1]\n",
      "Precision:  0.8410065947899775 \n",
      "Params:  [125, 56, 1] \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 150,52,1\n",
      "Accuracy: 0.5608308605341247; Precision: 0.8344536768869114; Own Metric: 0.8399962871720379\n",
      "\n",
      "2018-12-05 01:39:30\n",
      "Own Metric:  0.8400333391935793 \n",
      "Params:  [125, 52, 1]\n",
      "Accuracy:  0.56973293768546 \n",
      "Params:  [100, 54, 1]\n",
      "Precision:  0.8410065947899775 \n",
      "Params:  [125, 56, 1] \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 150,54,1\n",
      "Accuracy: 0.5563798219584569; Precision: 0.831625175022801; Own Metric: 0.839794712992501\n",
      "\n",
      "2018-12-05 01:41:08\n",
      "Own Metric:  0.8400333391935793 \n",
      "Params:  [125, 52, 1]\n",
      "Accuracy:  0.56973293768546 \n",
      "Params:  [100, 54, 1]\n",
      "Precision:  0.8410065947899775 \n",
      "Params:  [125, 56, 1] \n",
      "\n",
      "----------------------\n",
      "Thread: 3\n",
      "Params: 150,56,1\n",
      "Accuracy: 0.5548961424332344; Precision: 0.8310564312047992; Own Metric: 0.8398383570263976\n",
      "\n",
      "==========================\n",
      "==========================\n",
      "\n",
      "\n",
      "Thread:  3\n",
      "Own Metric:  0.8400333391935793 \n",
      "Params:  [125, 52, 1]\n",
      "Accuracy:  0.56973293768546 \n",
      "Params:  [100, 54, 1]\n",
      "Precision:  0.8410065947899775 \n",
      "Params:  [125, 56, 1] \n",
      "\n",
      "\n",
      "Ended at:\n",
      "2018-12-05 01:41:08\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "thread_list = []\n",
    "\n",
    "t1 = threading.Thread(target=gridResultOVR_RFC, args=(test_train_set, 100, 151, 25, 40, 45, 2, 1, 3, 3, 'log_ovrrfc_grid_1', 1))\n",
    "t2 = threading.Thread(target=gridResultOVR_RFC, args=(test_train_set, 100, 151, 25, 46, 51, 2, 1, 3, 3, 'log_ovrrfc_grid_2', 2))\n",
    "t3 = threading.Thread(target=gridResultOVR_RFC, args=(test_train_set, 100, 151, 25, 52, 57, 2, 1, 3, 3, 'log_ovrrfc_grid_3', 3))\n",
    "\n",
    "\n",
    "# Sticks the thread in a list so that it remains accessible\n",
    "thread_list.append(t1)\n",
    "thread_list.append(t2)\n",
    "thread_list.append(t3)\n",
    "\n",
    "# for thread in thread_list:\n",
    "#     thread.start()\n",
    "\n",
    "# for thread in thread_list:\n",
    "#     thread.join()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5578635014836796 0.828568414770195 0.8398930845586363\n"
     ]
    }
   ],
   "source": [
    "ovrrfc = OneVsRestClassifier(RandomForestClassifier(n_estimators=130, max_depth=43, n_jobs = -1))\n",
    "ovrrfc.fit(train_X, train_y)\n",
    "pred_ovrrfc = ovrrfc.predict(test_X)\n",
    "prec =  metrics.precision_score(test_y, pred_ovrrfc, average=\"samples\")\n",
    "acc = metrics.accuracy_score(test_y, pred_ovrrfc)\n",
    "mla = getMLA(test_y, pred_ovrrfc)\n",
    "print(acc, prec, mla)\n",
    "\n",
    "with open('dumped_ovrrfc.pkl', 'wb') as fid:\n",
    "    _pickle.dump(ovrrfc, fid)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
