{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import operator\n",
    "import time\n",
    "import datetime\n",
    "import platform\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeText(text, path, mode = 'w'):\n",
    "    with open (path, mode, encoding = 'utf-8') as textout:\n",
    "        textout.write((text))\n",
    "        \n",
    "def writeJson(json, path, mode = 'w'):\n",
    "    with open(path, mode) as file:\n",
    "        file.write(json.dumps(json))\n",
    "        \n",
    "def writeCsv(listOut, outputFile):\n",
    "    with open (outputFile, \"w\", newline='', encoding = 'utf-8') as outputfile:\n",
    "        writer = csv.writer(outputfile, delimiter = \",\")\n",
    "        for element in listOut:\n",
    "            writer.writerow(element)\n",
    "            \n",
    "def getTxt(path):\n",
    "    return open(path, 'r').read()\n",
    "\n",
    "def getCsv(path, delim = ','):\n",
    "    list_return = []\n",
    "    with open (path, encoding = 'utf-8') as file:\n",
    "        csvreader = csv.reader(file, delimiter = delim)        \n",
    "        for i, line in enumerate(csvreader):\n",
    "            list_return.append(line)\n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFloatCsv(path, delim = ','):\n",
    "    list_return = []\n",
    "    with open (path, encoding = 'utf-8') as file:\n",
    "        csvreader = csv.reader(file, delimiter = delim)        \n",
    "        for i, line in enumerate(csvreader):\n",
    "            list_return.append([float(x) for x in line])\n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    feat = getFloatCsv('..\\\\output\\\\feat.csv')\n",
    "else:\n",
    "    feat = getFloatCsv('../output/feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    label = getCsv('..\\\\output\\\\labels.csv')\n",
    "else:\n",
    "    label = getCsv('../output/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll = []\n",
    "# for line in label:\n",
    "#     for word in line:\n",
    "#         if word not in ll:\n",
    "#             ll.append(word)\n",
    "# len(ll)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(label)\n",
    "y = multilabel_binarizer.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.40620422,  0.37869263,  0.58084106, ...,  0.03137207,\n",
       "          0.64916992, -1.32333374],\n",
       "        [-0.50666809,  0.45892334,  0.73953247, ..., -0.08215332,\n",
       "          1.0402832 , -1.47055054],\n",
       "        [-0.44416809,  0.43939209,  0.61599731, ..., -0.01086426,\n",
       "          0.69067383, -1.39877319],\n",
       "        ...,\n",
       "        [ 2.33901978,  7.3309021 , -1.46138   , ..., -2.83006287,\n",
       "          7.28421021,  1.01919556],\n",
       "        [-1.52600098,  1.57382202,  2.0201416 , ..., -1.18414307,\n",
       "          1.93450928, -0.99139404],\n",
       "        [-1.51477051,  1.66415405,  1.97241211, ..., -1.46881104,\n",
       "          2.1239624 , -1.10540771]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dims training set:  (2694, 300) (2694, 125)\n",
      "Dims training set:  (674, 300) (674, 125)\n"
     ]
    }
   ],
   "source": [
    "print('Dims training set: ', train_X.shape, train_y.shape)\n",
    "print('Dims training set: ', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridResultRFC(data, n_est1, n_est2, n_est_grid, depth1, depth2, depth_grid, min_leaf1, min_leaf2, min_leaf_grid, filename = 'log_rf_grid', thread = 1):\n",
    "    train_X, test_X, train_y, test_y = data[0], data[1], data[2], data[3]\n",
    "    acc_best = 0\n",
    "    prec_best = 0\n",
    "    acc_params_best = [0,0,0]\n",
    "    prec_params_best = [0,0,0]\n",
    "    str_log = 'Started at:\\n' + datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S') + '\\nThread: ' + str(thread) + '\\n'\n",
    "    print(str_log)\n",
    "    est_runs = (n_est2-n_est1)/n_est_grid\n",
    "    depth_runs = (depth2-depth1)/depth_grid\n",
    "    leaf_runs = (min_leaf2-min_leaf1)/min_leaf_grid\n",
    "    str_tmp = 'Grid Search will test ' + str(est_runs*depth_runs*leaf_runs) + ' combinations.\\n'\n",
    "    str_log += str_tmp\n",
    "    print(str_tmp)\n",
    "    \n",
    "    est_act = n_est1\n",
    "    depth_act = depth1\n",
    "    leaf_act = min_leaf1\n",
    "    \n",
    "    while (est_act < n_est2):\n",
    "        depth_act = depth1\n",
    "        while (depth_act < depth2):\n",
    "            leaf_act = min_leaf1\n",
    "            while (leaf_act < min_leaf2):\n",
    "                rf = RandomForestClassifier(n_estimators=est_act, max_depth=depth_act, min_samples_leaf=leaf_act)\n",
    "                rf.fit(train_X, train_y)\n",
    "                pred_rf = rf.predict(test_X)        \n",
    "                prec =  metrics.precision_score(test_y, pred_rf, average=\"samples\")\n",
    "                acc = metrics.accuracy_score(test_y, pred_rf)\n",
    "                print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                str_tmp = '----------------------\\n'+ 'Thread: ' + str(thread) + '\\n' + 'Params: '+str(est_act)+','+str(depth_act)+','+str(leaf_act)+'\\n'+'Accuracy: '+str(acc)+';'+' Precision: '+str(prec)+'\\n'\n",
    "                print('Accuracy: ', str(acc_best), '\\nParams: ', str(acc_params_best))\n",
    "                print('Precision: ', str(prec_best), '\\nParams: ', str(prec_params_best), '\\n')\n",
    "                str_log += str_tmp\n",
    "                print(str_tmp)\n",
    "                if acc_best <= acc:\n",
    "                    acc_best = acc\n",
    "                    acc_params_best = [est_act,depth_act,leaf_act]\n",
    "                if prec_best <= prec:\n",
    "                    prec_best = prec\n",
    "                    prec_params_best = [est_act,depth_act,leaf_act]\n",
    "                leaf_act += min_leaf_grid\n",
    "            depth_act += depth_grid\n",
    "        est_act += n_est_grid\n",
    "        \n",
    "    str_tmp = '==========================\\n==========================\\n\\n\\n'+'Accuracy: '+str(acc_best)+'\\nParams: '+str(acc_params_best) + '\\n' + 'Precision: '+str(prec_best)+'\\nParams: '+str(prec_params_best)+'\\n'+'Ended at:\\n'+datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    str_log += str_tmp\n",
    "    \n",
    "    print('==========================\\n==========================\\n\\n')\n",
    "    print('Thread: ', thread)\n",
    "    print('Accuracy: ', str(acc_best), '\\nParams: ', str(acc_params_best))\n",
    "    print('Precision: ', str(prec_best), '\\nParams: ', str(prec_params_best), '\\n\\n')\n",
    "    print('Ended at:\\n' + datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    writeText(str_log, ('..\\\\output\\\\' + filename + '.txt'))             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_set = [train_X, test_X, train_y, test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "thread_list = []\n",
    "\n",
    "t1 = threading.Thread(target=gridResultRFC, args=(test_train_set, 100, 151, 25, 40, 45, 2, 1, 3, 3, 'log_rf_grid_1.2', 1))\n",
    "t2 = threading.Thread(target=gridResultRFC, args=(test_train_set, 100, 151, 25, 46, 51, 2, 1, 3, 3, 'log_rf_grid_2.2', 2))\n",
    "t3 = threading.Thread(target=gridResultRFC, args=(test_train_set, 100, 151, 25, 52, 57, 2, 1, 3, 3, 'log_rf_grid_3.2', 3))\n",
    "t4 = threading.Thread(target=gridResultRFC, args=(test_train_set, 175, 226, 25, 40, 45, 2, 1, 3, 3, 'log_rf_grid_4.2', 4))\n",
    "t5 = threading.Thread(target=gridResultRFC, args=(test_train_set, 175, 226, 25, 46, 51, 2, 1, 3, 3, 'log_rf_grid_5.2', 5))\n",
    "t6 = threading.Thread(target=gridResultRFC, args=(test_train_set, 175, 226, 25, 52, 57, 2, 1, 3, 3, 'log_rf_grid_6.2', 6))\n",
    "\n",
    "\n",
    "# Sticks the thread in a list so that it remains accessible\n",
    "thread_list.append(t1)\n",
    "thread_list.append(t2)\n",
    "thread_list.append(t3)\n",
    "thread_list.append(t4)\n",
    "thread_list.append(t5)\n",
    "thread_list.append(t6)\n",
    "\n",
    "# for thread in thread_list:\n",
    "#     thread.start()\n",
    "\n",
    "# for thread in thread_list:\n",
    "#     thread.join()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6068249258160238 0.8416859352319291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=120, max_depth=50, min_samples_leaf=1)\n",
    "rf.fit(train_X, train_y)\n",
    "pred_rf = rf.predict(test_X)\n",
    "prec =  metrics.precision_score(test_y, pred_rf, average=\"samples\")\n",
    "acc = metrics.accuracy_score(test_y, pred_rf)\n",
    "print(acc, prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle\n",
    "# save the classifier\n",
    "with open('my_dumped_classifier.pkl', 'wb') as fid:\n",
    "    _pickle.dump(rf, fid)    \n",
    "with open('my_dumped_binarizer.pkl', 'wb') as fid:\n",
    "    _pickle.dump(multilabel_binarizer, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it again\n",
    "with open('my_dumped_classifier.pkl', 'rb') as fid:\n",
    "    rf_load = _pickle.load(fid)\n",
    "with open('my_dumped_binarizer.pkl', 'rb') as fid:\n",
    "    bin_load = _pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6068249258160238 0.8416859352319291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pred_rf2 = rf_load.predict(test_X)\n",
    "prec =  metrics.precision_score(test_y, pred_rf2, average=\"samples\")\n",
    "acc = metrics.accuracy_score(test_y, pred_rf2)\n",
    "print(acc, prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rf2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels:  (' health', ' social issues', 'health_medical_pharma')\n",
      "Actual Labels:  (' health', ' social issues', 'health_medical_pharma')\n",
      "==================\n",
      "Predicted Labels:  (' environment', 'disaster_accident')\n",
      "Actual Labels:  (' environment', 'disaster_accident')\n",
      "==================\n",
      "Predicted Labels:  (' unemployment', ' workforce', 'labor')\n",
      "Actual Labels:  (' unemployment', ' workforce', 'labor')\n",
      "==================\n",
      "Predicted Labels:  (' female labor force in the muslim world', ' workforce', ' world bank population', 'social issues')\n",
      "Actual Labels:  (' female labor force in the muslim world', ' world bank population', 'social issues')\n",
      "==================\n",
      "Predicted Labels:  (' world bank population', 'social issues')\n",
      "Actual Labels:  (' law_crime', ' world bank population', 'social issues')\n",
      "==================\n",
      "Predicted Labels:  (' demography', 'social issues')\n",
      "Actual Labels:  (' demography', 'social issues')\n",
      "==================\n",
      "Predicted Labels:  (' international standard industrial classification', 'national accounts')\n",
      "Actual Labels:  (' international standard industrial classification', 'national accounts')\n",
      "==================\n",
      "Predicted Labels:  (' education', ' social issues', 'education')\n",
      "Actual Labels:  (' education', ' social issues', 'education')\n",
      "==================\n",
      "Predicted Labels:  (' primary education', 'education')\n",
      "Actual Labels:  (' primary education', 'education')\n",
      "==================\n",
      "Predicted Labels:  ()\n",
      "Actual Labels:  (' disaster_accident', 'environment')\n",
      "==================\n",
      "Predicted Labels:  (' demography', ' health', 'social issues')\n",
      "Actual Labels:  (' demography', ' health', 'social issues')\n",
      "==================\n",
      "Predicted Labels:  (' world bank population', 'social issues')\n",
      "Actual Labels:  (' culture', ' structure', ' world bank population', 'social issues')\n",
      "==================\n",
      "Predicted Labels:  (' education', ' human behavior', ' secondary education', 'education')\n",
      "Actual Labels:  (' education', ' human behavior', ' secondary education', 'education')\n",
      "==================\n",
      "Predicted Labels:  (' credit', ' debt', ' external debt', ' financial law', ' loans', ' world bank ppg', 'money')\n",
      "Actual Labels:  (' aid', ' credit', ' debt', ' external debt', ' loans', ' world bank ppg', 'money')\n",
      "==================\n",
      "Predicted Labels:  (' international standard industrial classification', 'national accounts')\n",
      "Actual Labels:  (' business', ' international standard industrial classification', 'national accounts')\n",
      "==================\n",
      "Predicted Labels:  (' employment', ' social issues', ' unemployment', 'labor')\n",
      "Actual Labels:  (' employment', ' social issues', ' unemployment', 'labor')\n",
      "==================\n",
      "Predicted Labels:  ('disaster_accident',)\n",
      "Actual Labels:  ('disaster_accident',)\n",
      "==================\n",
      "Predicted Labels:  (' education', ' human behavior', ' labor', 'education')\n",
      "Actual Labels:  (' education', ' human behavior', ' labor', 'education')\n",
      "==================\n",
      "Predicted Labels:  (' international labour organization', ' unemployment', ' united nations', ' workforce', 'labor')\n",
      "Actual Labels:  (' international labour organization', ' unemployment', ' united nations', ' workforce', 'labor')\n",
      "==================\n",
      "Predicted Labels:  (' macroeconomics', 'national accounts')\n",
      "Actual Labels:  (' macroeconomics', 'national accounts')\n",
      "==================\n",
      "Predicted Labels:  (' world bank population', 'social issues')\n",
      "Actual Labels:  (' world bank population', 'social issues')\n",
      "==================\n",
      "Predicted Labels:  (' credit', ' debt', ' external debt', ' government debt', ' international macroeconomics', 'money')\n",
      "Actual Labels:  (' debt', ' external debt', ' government debt', ' international macroeconomics', ' world bank net', 'money')\n",
      "==================\n",
      "Predicted Labels:  ('environment',)\n",
      "Actual Labels:  ('environment',)\n",
      "==================\n",
      "Predicted Labels:  (' female labor force in the muslim world', ' workforce', 'social issues')\n",
      "Actual Labels:  (' female labor force in the muslim world', ' workforce', 'social issues')\n",
      "==================\n",
      "Predicted Labels:  (' international standard industrial classification', 'labor')\n",
      "Actual Labels:  (' international standard industrial classification', 'labor')\n",
      "==================\n",
      "Predicted Labels:  ()\n",
      "Actual Labels:  (' development aid', ' development assistance committee', ' international development', ' international relations', ' organisation for economic co-operation and development', 'aid')\n",
      "==================\n",
      "Predicted Labels:  (' expenditure', ' labor', ' money', ' national accounts', ' politics', ' social issues', 'health_medical_pharma')\n",
      "Actual Labels:  (' expenditure', ' labor', ' money', ' national accounts', ' politics', ' social issues', 'health_medical_pharma')\n",
      "==================\n",
      "Predicted Labels:  (' education', ' primary education', 'education')\n",
      "Actual Labels:  (' education', ' primary education', 'education')\n",
      "==================\n",
      "Predicted Labels:  ('environment',)\n",
      "Actual Labels:  ('environment',)\n",
      "==================\n",
      "Predicted Labels:  (' culture', ' education', ' human behavior', ' social issues', 'education')\n",
      "Actual Labels:  (' culture', ' education', ' human behavior', ' social issues', 'education')\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "cnt_lb = 0\n",
    "detrans_pred = bin_load.inverse_transform(pred_rf2[400:430])\n",
    "detrans_y = bin_load.inverse_transform(test_y[400:430])\n",
    "while cnt_lb < 30:\n",
    "    print('Predicted Labels: ', detrans_pred[cnt_lb])\n",
    "    print('Actual Labels: ', detrans_y[cnt_lb])\n",
    "    print('==================')\n",
    "    cnt_lb += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n = 1\n",
    "# n_max =50\n",
    "# l_acc, l_prec = [], []\n",
    "# acc_n_best, prec_n_best, acc_best, prec_best = 0, 0, 0, 0\n",
    "# while n < 50:\n",
    "#     print('Evaluate n=', n)\n",
    "#     knn = KNeighborsClassifier(n_neighbors=n)\n",
    "#     knn.fit(train_X, train_y)\n",
    "    \n",
    "#     pred_knn = knn.predict(test_X)\n",
    "#     prec =  metrics.precision_score(test_y, pred_knn, average=\"samples\")\n",
    "#     acc = metrics.accuracy_score(test_y, pred_knn)\n",
    "    \n",
    "#     l_acc.append(acc)\n",
    "#     l_prec.append(prec)\n",
    "    \n",
    "#     if acc_best <= acc:\n",
    "#         acc_best = acc\n",
    "#         acc_n_best = n\n",
    "#     if prec_best <= prec:\n",
    "#         prec_best = prec\n",
    "#         prec_n_best = n\n",
    "        \n",
    "#     n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# l_prec, l_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_n_best, acc_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prec_n_best, prec_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_knn = knn.predict(test_X)\n",
    "# print('Precision: ', metrics.precision_score(test_y, pred_knn, average=\"samples\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy: ', metrics.accuracy_score(test_y, pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnevsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from numpy import array\n",
    "\n",
    "# clf = OneVsRestClassifier(SVC(probability=True, gamma='auto'))\n",
    "# clf.fit(train_X, train_y)\n",
    "# predictions = clf.predict(test_X)\n",
    "\n",
    "# my_metrics = metrics.classification_report(test_y, predictions)\n",
    "\n",
    "# # print(my_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clf.score(test_X, test_y, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mclf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mclf.fit(train_X, train_y)\n",
    "# predictionsm = mclf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Precision: ', metrics.precision_score(test_y, predictionsm,average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy: ', metrics.accuracy_score(test_y, predictionsm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridResultNN(data, hl1, hl2, hlg, filename, thread):\n",
    "    train_X, test_X, train_y, test_y = data[0], data[1], data[2], data[3]\n",
    "    hla = hl1\n",
    "    l_acc, l_prec = [], []\n",
    "    str_tmp = ''\n",
    "    acc_n_best, prec_n_best, acc_best, prec_best = 0, 0, 0, 0\n",
    "    str_log = 'Started at:\\n' + datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S') + '\\nThread: ' + str(thread) + '\\n'\n",
    "    print(str_log)\n",
    "    while hla < hl2:\n",
    "        print('Evaluate Hidden Layers = ', hla)\n",
    "        mclf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(hla,), random_state=1)\n",
    "        mclf.fit(train_X, train_y)\n",
    "        predictionsm = mclf.predict(test_X)\n",
    "        prec =  metrics.precision_score(test_y, predictionsm, average=\"samples\")\n",
    "        acc = metrics.accuracy_score(test_y, predictionsm)\n",
    "\n",
    "        l_acc.append(acc)\n",
    "        l_prec.append(prec)\n",
    "    \n",
    "        if acc_best <= acc:\n",
    "            acc_best = acc\n",
    "            acc_n_best = hla\n",
    "        if prec_best <= prec:\n",
    "            prec_best = prec\n",
    "            prec_n_best = hla\n",
    "        \n",
    "        str_tmp += 'Evaluate Hidden Layers = ' + str(hla) + '\\n' + 'Acc: ' + str(acc) + ', Prec: ' + str(prec) + '\\n'\n",
    "        print(str_tmp)\n",
    "        str_log += str_tmp\n",
    "        hla += hlg\n",
    "        \n",
    "    print('==========================\\n==========================\\n\\n')\n",
    "    print('Thread: ', thread)\n",
    "    print('Accuracy: ', str(acc_best), '\\nParams: ', str(acc_n_best))\n",
    "    print('Precision: ', str(prec_best), '\\nParams: ', str(prec_n_best), '\\n\\n')\n",
    "        \n",
    "    str_tmp = ('Ended at:\\n' + datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    print(str_tmp)\n",
    "    str_log += '\\n' + str_tmp\n",
    "    \n",
    "    writeText(str_log, ('..\\\\output\\\\' + filename + '.txt')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "thread_list = []\n",
    "\n",
    "t1 = threading.Thread(target=gridResultNN, args=(test_train_set, 2, 51, 2, 'log_nn_grid_1', 1))\n",
    "t2 = threading.Thread(target=gridResultNN, args=(test_train_set, 52, 200, 10, 'log_nn_grid_2', 2))\n",
    "t3 = threading.Thread(target=gridResultNN, args=(test_train_set, 220, 500, 30, 'log_nn_grid_3', 3))\n",
    "t4 = threading.Thread(target=gridResultNN, args=(test_train_set, 520, 1000, 50, 'log_nn_grid_4', 4))\n",
    "t5 = threading.Thread(target=gridResultNN, args=(test_train_set, 1000, 1800, 75, 'log_nn_grid_5', 5))\n",
    "t6 = threading.Thread(target=gridResultNN, args=(test_train_set, 1800, 3000, 180, 'log_nn_grid_6', 6))\n",
    "\n",
    "\n",
    "# Sticks the thread in a list so that it remains accessible\n",
    "thread_list.append(t1)\n",
    "thread_list.append(t2)\n",
    "thread_list.append(t3)\n",
    "thread_list.append(t4)\n",
    "thread_list.append(t5)\n",
    "thread_list.append(t6)\n",
    "\n",
    "# # Starts threads\n",
    "# for thread in thread_list:\n",
    "#     thread.start()\n",
    "\n",
    "# # This blocks the calling thread until the thread whose join() method is called is terminated.\n",
    "# # From http://docs.python.org/2/library/threading.html#thread-objects\n",
    "# for thread in thread_list:\n",
    "#     thread.join()\n",
    "\n",
    "# Demonstrates that the main process waited for threads to complete\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
