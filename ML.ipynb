{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import operator\n",
    "import time\n",
    "import datetime\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeText(text, path, mode = 'w'):\n",
    "    with open (path, mode, encoding = 'utf-8') as textout:\n",
    "        textout.write((text))\n",
    "        \n",
    "def writeJson(json, path, mode = 'w'):\n",
    "    with open(path, mode) as file:\n",
    "        file.write(json.dumps(json))\n",
    "        \n",
    "def writeCsv(listOut, outputFile):\n",
    "    with open (outputFile, \"w\", newline='', encoding = 'utf-8') as outputfile:\n",
    "        writer = csv.writer(outputfile, delimiter = \",\")\n",
    "        for element in listOut:\n",
    "            writer.writerow(element)\n",
    "            \n",
    "def getTxt(path):\n",
    "    return open(path, 'r').read()\n",
    "\n",
    "def getCsv(path, delim = ','):\n",
    "    list_return = []\n",
    "    with open (path, encoding = 'utf-8') as file:\n",
    "        csvreader = csv.reader(file, delimiter = delim)        \n",
    "        for i, line in enumerate(csvreader):\n",
    "            list_return.append(line)\n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFloatCsv(path, delim = ','):\n",
    "    list_return = []\n",
    "    with open (path, encoding = 'utf-8') as file:\n",
    "        csvreader = csv.reader(file, delimiter = delim)        \n",
    "        for i, line in enumerate(csvreader):\n",
    "            list_return.append([float(x) for x in line])\n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    feat = getFloatCsv('..\\\\output\\\\feat.csv')\n",
    "else:\n",
    "    feat = getFloatCsv('../output/feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    label = getCsv('..\\\\output\\\\labels.csv')\n",
    "else:\n",
    "    label = getCsv('../output/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(label)\n",
    "y = multilabel_binarizer.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.40620422,  0.37869263,  0.58084106, ...,  0.03137207,\n",
       "          0.64916992, -1.32333374],\n",
       "        [-0.50666809,  0.45892334,  0.73953247, ..., -0.08215332,\n",
       "          1.0402832 , -1.47055054],\n",
       "        [-0.44416809,  0.43939209,  0.61599731, ..., -0.01086426,\n",
       "          0.69067383, -1.39877319],\n",
       "        ...,\n",
       "        [-1.87205505,  9.57649994,  5.45687866, ..., -7.40915108,\n",
       "          4.59017944, -0.98852539],\n",
       "        [-1.97251892,  9.65673065,  5.61557007, ..., -7.52267647,\n",
       "          4.98129272, -1.13574219],\n",
       "        [-1.91001892,  9.6371994 ,  5.49203491, ..., -7.45138741,\n",
       "          4.63168335, -1.06396484]]), array([[0, 1, 0, ..., 0, 1, 0],\n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dims training set:  (375, 300) (375, 158)\n",
      "Dims training set:  (125, 300) (125, 158)\n"
     ]
    }
   ],
   "source": [
    "print('Dims training set: ', train_X.shape, train_y.shape)\n",
    "print('Dims training set: ', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=15,random_state=0)\n",
    "rf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = rf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9414464137170019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ', metrics.precision_score(test_y, pred_rf, average=\"samples\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.368\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(test_y, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8962183816183816\n"
     ]
    }
   ],
   "source": [
    "pred_knn = knn.predict(test_X)\n",
    "print('Precision: ', metrics.precision_score(test_y, pred_knn, average=\"samples\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.504\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(test_y, pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnevsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.83      0.91         6\n",
      "           2       1.00      0.75      0.86         4\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      0.47      0.64        15\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       1.00      1.00      1.00        63\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.86      0.75      0.80         8\n",
      "          11       0.00      0.00      0.00        11\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       1.00      0.50      0.67         6\n",
      "          15       0.93      0.87      0.90        15\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      1.00      1.00         4\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       1.00      0.33      0.50         6\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       1.00      0.67      0.80         6\n",
      "          23       0.50      0.33      0.40         3\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       0.93      0.87      0.90        15\n",
      "          26       0.00      0.00      0.00         2\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       1.00      0.88      0.93        16\n",
      "          29       0.00      0.00      0.00         3\n",
      "          30       0.71      0.85      0.77        20\n",
      "          31       1.00      0.44      0.62         9\n",
      "          32       0.50      0.50      0.50         2\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       1.00      1.00      1.00         1\n",
      "          35       0.00      0.00      0.00         3\n",
      "          36       1.00      0.25      0.40         4\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       1.00      0.96      0.98        28\n",
      "          39       1.00      0.50      0.67         2\n",
      "          40       1.00      0.50      0.67         2\n",
      "          41       1.00      0.85      0.92        13\n",
      "          42       0.67      0.67      0.67         3\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       1.00      1.00      1.00         3\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         4\n",
      "          47       1.00      0.88      0.93        16\n",
      "          48       0.00      0.00      0.00         3\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       0.00      0.00      0.00         3\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         3\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.86      1.00      0.92         6\n",
      "          56       1.00      1.00      1.00         7\n",
      "          57       1.00      0.33      0.50         6\n",
      "          58       0.50      0.50      0.50         2\n",
      "          59       0.96      0.79      0.87        34\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       0.68      1.00      0.81        15\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.75      0.67      0.71         9\n",
      "          64       0.00      0.00      0.00         7\n",
      "          65       0.68      1.00      0.81        15\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       1.00      0.80      0.89        15\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.83      0.71      0.77         7\n",
      "          70       1.00      1.00      1.00         3\n",
      "          71       1.00      0.86      0.92         7\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         5\n",
      "          74       0.00      0.00      0.00         3\n",
      "          75       0.97      0.93      0.95        74\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       1.00      0.73      0.84        11\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       1.00      0.75      0.86         4\n",
      "          80       1.00      1.00      1.00         4\n",
      "          81       1.00      1.00      1.00         1\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       1.00      0.83      0.90        23\n",
      "          85       0.91      0.83      0.87        12\n",
      "          86       0.00      0.00      0.00         7\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       1.00      0.50      0.67         6\n",
      "          89       0.60      0.60      0.60         5\n",
      "          90       0.00      0.00      0.00         3\n",
      "          91       1.00      0.83      0.91         6\n",
      "          92       0.50      0.50      0.50         2\n",
      "          93       1.00      1.00      1.00         2\n",
      "          94       0.00      0.00      0.00        11\n",
      "          95       1.00      1.00      1.00         8\n",
      "          96       0.71      0.81      0.76        21\n",
      "          97       0.00      0.00      0.00         2\n",
      "          98       0.00      0.00      0.00         7\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.00      0.00      0.00         4\n",
      "         101       1.00      1.00      1.00         4\n",
      "         102       1.00      0.83      0.90        23\n",
      "         103       1.00      0.25      0.40         4\n",
      "         104       1.00      0.98      0.99        42\n",
      "         105       1.00      1.00      1.00         3\n",
      "         106       0.00      0.00      0.00         4\n",
      "         107       0.50      0.33      0.40         3\n",
      "         108       1.00      1.00      1.00        14\n",
      "         109       1.00      0.25      0.40         4\n",
      "         110       0.00      0.00      0.00         3\n",
      "         111       1.00      1.00      1.00         5\n",
      "         112       0.00      0.00      0.00         4\n",
      "         113       1.00      0.50      0.67         2\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       1.00      1.00      1.00         4\n",
      "         116       1.00      1.00      1.00         4\n",
      "         117       1.00      0.60      0.75         5\n",
      "         118       1.00      0.50      0.67         4\n",
      "         119       1.00      1.00      1.00         3\n",
      "         120       0.90      0.79      0.84        24\n",
      "         121       1.00      0.50      0.67         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         7\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         1\n",
      "         126       1.00      1.00      1.00         3\n",
      "         127       1.00      0.75      0.86         8\n",
      "         128       0.93      0.87      0.90        15\n",
      "         129       1.00      1.00      1.00         8\n",
      "         130       0.00      0.00      0.00         3\n",
      "         131       0.00      0.00      0.00         1\n",
      "         132       0.00      0.00      0.00         3\n",
      "         133       1.00      1.00      1.00         3\n",
      "         134       0.00      0.00      0.00         2\n",
      "         135       1.00      1.00      1.00         4\n",
      "         136       1.00      1.00      1.00         5\n",
      "         137       0.50      0.50      0.50         2\n",
      "         138       1.00      0.75      0.86         8\n",
      "         139       1.00      0.60      0.75         5\n",
      "         140       1.00      1.00      1.00         3\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       1.00      0.97      0.98        65\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         1\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.97      0.97      0.97        31\n",
      "         147       0.00      0.00      0.00         2\n",
      "         148       1.00      1.00      1.00         4\n",
      "         149       1.00      0.88      0.94        17\n",
      "         150       0.00      0.00      0.00         1\n",
      "         151       1.00      0.17      0.29         6\n",
      "         152       1.00      0.60      0.75         5\n",
      "         153       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       1.00      1.00      1.00         3\n",
      "         156       0.96      0.96      0.96        52\n",
      "         157       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.94      0.75      0.83      1133\n",
      "   macro avg       0.57      0.48      0.51      1133\n",
      "weighted avg       0.83      0.75      0.78      1133\n",
      " samples avg       0.94      0.79      0.84      1133\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from numpy import array\n",
    "\n",
    "clf = OneVsRestClassifier(SVC(probability=True, gamma='auto'))\n",
    "clf.fit(train_X, train_y)\n",
    "predictions = clf.predict(test_X)\n",
    "\n",
    "my_metrics = metrics.classification_report(test_y, predictions)\n",
    "\n",
    "print(my_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.328\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(test_X, test_y, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclf.fit(train_X, train_y)\n",
    "predictionsm = mclf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7804645583174995\n"
     ]
    }
   ],
   "source": [
    "print('Precision: ', metrics.precision_score(test_y, predictionsm,average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.168\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(test_y, predictionsm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
