{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/user1-2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/user1-2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/user1-2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2019-01-17 16:10:11\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import datetime\n",
    "import nltk\n",
    "import requests\n",
    "import _pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk import ngrams, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print('_______________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements_wu.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Def Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTxt(path):  \n",
    "    return open(path, 'r').read()\n",
    "\n",
    "# function to open csv files with the right encoding\n",
    "def getCsv(path, delim = ',', enc = 'utf-8'):          \n",
    "    list_return = []\n",
    "    with open (path, encoding = enc) as file:\n",
    "        csvreader = csv.reader(file, delimiter = delim)\n",
    "        for line in csvreader:\n",
    "            list_return.append(line)\n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fillerwords = getTxt('..//input//fillerwords.txt').split(',') + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeString(title, desc):\n",
    "    print('Started at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    print('Tokenisation is running.')\n",
    "    global list_fillerwords\n",
    "#     string_to_clean = title + ' ' + desc\n",
    "    string_to_clean = desc\n",
    "    porterstemmer = PorterStemmer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    \n",
    "    list_token = nltk.word_tokenize(''.join([x for x in string_to_clean if not x.isdigit()]).replace('-',' ').replace('.','').replace(',','').replace('%','').replace(';',' ').replace('/', ' ').replace('(','').replace(')',''))\n",
    "    \n",
    "    for word in list_fillerwords:\n",
    "        while (word in list_token):\n",
    "            list_token.remove(word)\n",
    "            \n",
    "    for i, word in enumerate(list_token):\n",
    "        list_token[i] = list_token[i].lower()\n",
    "        lemmatizer.lemmatize(porterstemmer.stem(list_token[i]))\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return list_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for summing up single vectors (=words) in a vectorlist\n",
    "def sumVect(list_vect):\n",
    "    try:\n",
    "        for i, elem in enumerate(list_vect):\n",
    "            if not elem:\n",
    "                del list_vect[i]\n",
    "        \n",
    "        int_len_vect = len(list_vect[0])\n",
    "        list_vect_sum = [0] * int_len_vect\n",
    "        for vect in list_vect:\n",
    "            for i, dim in enumerate(vect):\n",
    "                list_vect_sum[i] += float(dim)\n",
    "        return(list_vect_sum)\n",
    "    except Exception as e:\n",
    "        print(list_vect)\n",
    "        print(i)\n",
    "        print(list_vect_sum)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeStringList(list_string):\n",
    "    print('Vectorisation is running.')\n",
    "    adress = 'http://word2vec.ai.wu.ac.at/googlenews/model?word='\n",
    "    feat_words = []\n",
    "    \n",
    "    for str_elem in list_string:\n",
    "        word = str_elem.strip() \n",
    "        try:\n",
    "            feat_words.append([float(x) for x in requests.get((adress+word)).text.replace(' ','').replace('[','').replace(']','').split(',')])\n",
    "        except:\n",
    "            try:\n",
    "                feat_words.append([float(x) for x in requests.get((adress+word.title())).text.replace(' ','').replace('[','').replace(']','').split(',')])\n",
    "            except Exception as e:\n",
    "                feat_words.append([])\n",
    "                           \n",
    "    if feat_words:\n",
    "        list_return = sumVect(feat_words)\n",
    "        \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelDataRFC(vect):\n",
    "    print('Creating labels.')\n",
    "        \n",
    "    with open('dumped_randomforestclassifier.pkl', 'rb') as fid:\n",
    "        rf_load = _pickle.load(fid)\n",
    "    with open('dumped_binarizer.pkl', 'rb') as fid:\n",
    "        bin_load = _pickle.load(fid)\n",
    "    \n",
    "    np_in = [vect]\n",
    "    X = np.array(np_in)\n",
    "    pred_rf = rf_load.predict(X)\n",
    "    pred_label = bin_load.inverse_transform(pred_rf)\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelDataOVRkNN(vect):\n",
    "    print('Creating labels.')\n",
    "        \n",
    "    with open('dumped_ovrknn20.pkl', 'rb') as fid:\n",
    "        rf_load = _pickle.load(fid)\n",
    "    with open('dumped_binarizer.pkl', 'rb') as fid:\n",
    "        bin_load = _pickle.load(fid)\n",
    "    \n",
    "    np_in = [vect]\n",
    "    X = np.array(np_in)\n",
    "    pred_rf = rf_load.predict(X)\n",
    "    pred_label = bin_load.inverse_transform(pred_rf)\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelDataOVRRFC(vect):\n",
    "    print('Creating labels.')\n",
    "        \n",
    "    with open('dumped_ovrrfc.pkl', 'rb') as fid:\n",
    "        rf_load = _pickle.load(fid)\n",
    "    with open('dumped_binarizer.pkl', 'rb') as fid:\n",
    "        bin_load = _pickle.load(fid)\n",
    "    \n",
    "    np_in = [vect]\n",
    "    X = np.array(np_in)\n",
    "    pred_rf = rf_load.predict(X)\n",
    "    pred_label = bin_load.inverse_transform(pred_rf)\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelDataVoting(vect):\n",
    "    print('Creating labels.')\n",
    "        \n",
    "    with open('dumped_randomforestclassifier.pkl', 'rb') as fid:\n",
    "        rf_load = _pickle.load(fid)\n",
    "    with open('dumped_ovrrfc.pkl', 'rb') as fid:\n",
    "        ovrrf_load = _pickle.load(fid)\n",
    "    with open('dumped_ovrknn20.pkl', 'rb') as fid:\n",
    "        ovrknn_load = _pickle.load(fid)\n",
    "    with open('dumped_binarizer.pkl', 'rb') as fid:\n",
    "        bin_load = _pickle.load(fid)\n",
    "    \n",
    "    np_in = [vect]\n",
    "    X = np.array(np_in)\n",
    "    pred_rf = rf_load.predict(X)\n",
    "    pred_ovrrf = ovrrf_load.predict(X)\n",
    "    pred_ovrknn = ovrknn_load.predict(X)\n",
    "    \n",
    "    pred_label = ((pred_rf+pred_ovrrf+pred_ovrknn)/3)\n",
    "    for i, label in enumerate(pred_label[0]):\n",
    "        if label > 0.5:\n",
    "            pred_label[0][i] = 1\n",
    "        else:\n",
    "            pred_label[0][i] = 0\n",
    "        \n",
    "        \n",
    "    pred_out = bin_load.inverse_transform(pred_label)\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return pred_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Labor force participation rate, female (% of female population ages 15+) (modeled ILO estimate), countries grouped by income levels'\n",
    "describtion = 'Labor force participation rate is the proportion of the population ages 15 and older that is economically active: all people who supply labor for the production of goods and services during a specified period.'\n",
    "# title = 'CO2 emissions (metric tons per capita)'\n",
    "# describtion = 'Carbon dioxide emissions are those stemming from the burning of fossil fuels and the manufacture of cement. They include carbon dioxide produced during consumption of solid, liquid, and gas fuels and gas flaring. Government reaction taxes issue '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2019-01-17 16:10:11.678558\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:10:14.450675\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:10:14.555203\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2019-01-17 16:10:17.332287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[()]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDataRFC(vectorizeStringList(tokenizeString(title, describtion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2019-01-17 16:10:17.375618\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:10:17.378506\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:10:17.478090\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator _ConstantPredictor from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2019-01-17 16:10:56.418872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' ageing',\n",
       "  ' cpia',\n",
       "  ' demographic economics',\n",
       "  ' demography',\n",
       "  ' disaster_accident',\n",
       "  ' economics',\n",
       "  ' energy development',\n",
       "  ' energy economics',\n",
       "  ' environment',\n",
       "  ' expense',\n",
       "  ' female labor force in the muslim world',\n",
       "  ' government',\n",
       "  ' health',\n",
       "  ' health_medical_pharma',\n",
       "  ' hiv',\n",
       "  ' hospitality_recreation',\n",
       "  ' human interest',\n",
       "  ' human migration',\n",
       "  ' law_crime',\n",
       "  ' medicine',\n",
       "  ' money',\n",
       "  ' nature',\n",
       "  ' population',\n",
       "  ' religion_belief',\n",
       "  ' taxation in the united states',\n",
       "  ' technology_internet',\n",
       "  ' tertiary education',\n",
       "  ' unemployment',\n",
       "  ' united nations development group',\n",
       "  ' workforce',\n",
       "  ' world bank cpia',\n",
       "  ' world bank labor',\n",
       "  ' world bank number',\n",
       "  ' world bank population',\n",
       "  'disaster_accident',\n",
       "  'environment',\n",
       "  'health_medical_pharma',\n",
       "  'law_crime',\n",
       "  'macroeconomics',\n",
       "  'social issues',\n",
       "  'technology_internet')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDataOVRRFC(vectorizeStringList(tokenizeString(title, describtion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2019-01-17 16:10:56.528598\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:10:56.531618\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:10:56.632977\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator _ConstantPredictor from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2019-01-17 16:11:38.546702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' female labor force in the muslim world',\n",
       "  ' unemployment',\n",
       "  ' united nations development group',\n",
       "  ' workforce',\n",
       "  ' world bank labor',\n",
       "  'social issues')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDataVoting(vectorizeStringList(tokenizeString(title, describtion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2019-01-17 16:11:38.677289\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:11:38.679619\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:11:38.784558\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator _ConstantPredictor from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2019-01-17 16:11:39.692106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' female labor force in the muslim world',\n",
       "  ' international labour organization',\n",
       "  ' unemployment',\n",
       "  ' united nations',\n",
       "  ' united nations development group',\n",
       "  ' workforce',\n",
       "  ' world bank labor',\n",
       "  'social issues')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDataOVRkNN(vectorizeStringList(tokenizeString(title, describtion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...some more test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcases = getCsv('single_cases2.csv', delim = ';', enc = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case index  0\n",
      "Started at  2019-01-17 16:11:39.733947\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:11:39.734805\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:11:39.761613\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2019-01-17 16:11:41.761595\n",
      "Started at  2019-01-17 16:11:41.798375\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:11:41.799597\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:11:41.826550\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator _ConstantPredictor from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2019-01-17 16:12:20.722931\n",
      "Started at  2019-01-17 16:12:20.826234\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:12:20.827273\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:12:20.858047\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.19.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2019-01-17 16:12:21.782548\n",
      "Started at  2019-01-17 16:12:21.786308\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:12:21.787194\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:12:21.813190\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:13:03.977530\n",
      "[[()], [(' cpia', ' demography', ' disaster_accident', ' environment', ' expense', ' government', ' health', ' health_medical_pharma', ' hiv', ' human interest', ' infant', ' law_crime', ' medicine', ' population', ' rtt', ' technology_internet', ' world bank number', 'disaster_accident', 'health_medical_pharma', 'human interest', 'law_crime')], [(' demography', ' health')], [(' demography', ' health')]]\n",
      "Case index  1\n",
      "Started at  2019-01-17 16:13:04.105283\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:13:04.106259\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:13:04.114924\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:13:06.225976\n",
      "Started at  2019-01-17 16:13:06.248797\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:13:06.250342\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:13:06.261395\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:13:45.860011\n",
      "Started at  2019-01-17 16:13:45.953551\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:13:45.954780\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:13:45.962688\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:13:46.929902\n",
      "Started at  2019-01-17 16:13:46.938094\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:13:46.939173\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:13:46.949883\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:14:28.873363\n",
      "[[()], [(' cpia', ' environment', ' government', ' health', ' labor', ' law', ' law_crime', ' tax', 'disaster_accident')], [(' business', ' freight transport', ' international relations')], [()]]\n",
      "Case index  2\n",
      "Started at  2019-01-17 16:14:28.998507\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:14:28.999412\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:14:29.021621\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:14:30.800774\n",
      "Started at  2019-01-17 16:14:30.819679\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:14:30.820486\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:14:30.843712\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:15:09.765738\n",
      "Started at  2019-01-17 16:15:09.890213\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:15:09.891984\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:15:09.918792\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:15:10.839876\n",
      "Started at  2019-01-17 16:15:10.845948\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:15:10.847338\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:15:10.875898\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:15:52.612966\n",
      "[[()], [(' chemistry', ' climate change policy', ' climatology', ' disaster_accident', ' energy development', ' energy economics', ' environment', ' fossil fuel', ' fuel', ' fuels', ' government', ' greenhouse gas', ' greenhouse gases', ' health_medical_pharma', ' human interest', ' low-carbon economy', ' nature', ' technology_internet', ' universe', 'disaster_accident', 'environment')], [(' climate change policy', ' fuels', ' greenhouse gases', ' nature', ' universe', 'environment')], [(' climate change policy', ' fuels', ' greenhouse gases', ' nature', ' universe', 'environment')]]\n",
      "Case index  3\n",
      "Started at  2019-01-17 16:15:52.723995\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:15:52.724917\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:15:52.746811\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:15:54.852365\n",
      "Started at  2019-01-17 16:15:54.882385\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:15:54.884381\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:15:54.911350\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:16:33.831218\n",
      "Started at  2019-01-17 16:16:33.941488\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:16:33.942611\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:16:33.967996\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:16:35.118720\n",
      "Started at  2019-01-17 16:16:35.123290\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:16:35.124191\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:16:35.149767\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:17:18.116025\n",
      "[[()], [(' cpia', ' disaster_accident', ' energy development', ' energy economics', ' environment', ' government', ' greenhouse gases', ' health', ' nature', ' social issues', ' technology_internet', ' universe', ' world bank cpia', ' world bank number', 'environment', 'health_medical_pharma', 'law_crime', 'technology_internet')], [(' nature', 'environment')], [(' nature', 'environment')]]\n",
      "Case index  4\n",
      "Started at  2019-01-17 16:17:18.240330\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:17:18.242406\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:17:18.302660\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:17:20.123135\n",
      "Started at  2019-01-17 16:17:20.136678\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:17:20.138355\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:17:20.193987\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:17:59.109344\n",
      "Started at  2019-01-17 16:17:59.209970\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:17:59.210999\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:17:59.271655\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:18:00.163620\n",
      "Started at  2019-01-17 16:18:00.176223\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:18:00.177279\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:18:00.235025\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:18:41.973350\n",
      "[[()], [(' chemistry', ' cpia', ' debt-to-gdp ratio', ' disaster_accident', ' energy development', ' environment', ' food and drink', ' government', ' health_medical_pharma', ' hospitality_recreation', ' human geography', ' international development', ' international trade', ' labor', ' macroeconomics', ' nature', ' rtt', ' security', ' technology_internet', ' transport', ' world bank cpia', 'disaster_accident', 'health_medical_pharma', 'hospitality_recreation', 'macroeconomics', 'politics', 'technology_internet')], [(' macroeconomics',)], [(' macroeconomics',)]]\n",
      "Case index  5\n",
      "Started at  2019-01-17 16:18:42.088704\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:18:42.090316\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:18:42.124233\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:18:44.061967\n",
      "Started at  2019-01-17 16:18:44.080274\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:18:44.081545\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:18:44.113799\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:19:23.048555\n",
      "Started at  2019-01-17 16:19:23.140927\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:19:23.142450\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:19:23.175936\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:19:24.258369\n",
      "Started at  2019-01-17 16:19:24.264411\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:19:24.265496\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:19:24.306310\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:20:06.962624\n",
      "[[()], [(' cpia', ' disaster_accident', ' economics', ' energy development', ' environment', ' government', ' health', ' health_medical_pharma', ' hiv', ' medicine', ' national accounts', ' real gross domestic product', ' religion_belief', ' social issues', ' tax', ' technology_internet', ' universe', 'disaster_accident', 'international trade', 'law_crime', 'macroeconomics', 'technology_internet')], [()], [()]]\n",
      "Case index  6\n",
      "Started at  2019-01-17 16:20:07.082217\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:20:07.083190\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:20:07.107713\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:20:09.289241\n",
      "Started at  2019-01-17 16:20:09.307756\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:20:09.308722\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:20:09.329883\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:20:48.195980\n",
      "Started at  2019-01-17 16:20:48.291736\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:20:48.292606\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:20:48.312299\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:20:49.236962\n",
      "Started at  2019-01-17 16:20:49.241844\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:20:49.243241\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:20:49.264341\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:21:31.079036\n",
      "[[()], [(' disaster_accident', ' economics', ' environment', ' health_medical_pharma', ' human interest', ' population', ' real gross domestic product', ' social issues', ' technology_internet', ' world bank population', 'disaster_accident', 'law_crime', 'macroeconomics', 'social issues')], [()], [()]]\n",
      "Case index  7\n",
      "Started at  2019-01-17 16:21:31.190034\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:21:31.190961\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:21:31.212783\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2019-01-17 16:21:32.951371\n",
      "Started at  2019-01-17 16:21:32.965334\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:21:32.966215\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:21:32.987344\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:22:11.885281\n",
      "Started at  2019-01-17 16:22:11.988059\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:22:11.989541\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:22:12.019539\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:22:13.018747\n",
      "Started at  2019-01-17 16:22:13.023578\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:22:13.024603\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:22:13.046726\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:22:54.941267\n",
      "[[()], [(' cpia', ' disaster_accident', ' environment', ' expenditure', ' general government', ' government', ' government final consumption expenditure', ' gross domestic product', ' health', ' household final consumption expenditure', ' medicine', ' military budget', ' politics', ' social statistics', ' tax', ' technology_internet', ' united kingdom national accounts – the blue book', ' world bank adjusted', ' world bank cpia', ' world bank gross', ' world bank number', 'health_medical_pharma', 'law_crime', 'social issues', 'tax')], [(' expenditure', ' final consumption expenditure', ' government final consumption expenditure', ' household final consumption expenditure', ' money', ' national accounts', 'politics')], [(' expenditure', ' government final consumption expenditure', ' household final consumption expenditure')]]\n",
      "Case index  8\n",
      "Started at  2019-01-17 16:22:55.050370\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:22:55.051461\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:22:55.089921\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:22:56.785732\n",
      "Started at  2019-01-17 16:22:56.803419\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:22:56.804648\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:22:56.843995\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:23:35.666024\n",
      "Started at  2019-01-17 16:23:35.758687\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:23:35.760381\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:23:35.800618\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:23:36.716009\n",
      "Started at  2019-01-17 16:23:36.719708\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:23:36.720962\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:23:36.759678\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:24:18.594164\n",
      "[[()], [(' chemistry', ' cpia', ' demography', ' disaster_accident', ' economics', ' environment', ' human behavior', ' human interest', ' medicine', ' money', ' religion_belief', ' rtt', ' social issues', ' teacher', ' technology_internet', ' tertiary education', 'disaster_accident', 'education', 'health_medical_pharma', 'law_crime')], [(' education', ' teacher', 'education')], [(' teacher', 'education')]]\n",
      "Case index  9\n",
      "Started at  2019-01-17 16:24:18.715496\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:24:18.717139\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:24:18.744691\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:24:21.102671\n",
      "Started at  2019-01-17 16:24:21.122247\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:24:21.124195\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:24:21.148593\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:25:00.107177\n",
      "Started at  2019-01-17 16:25:00.215013\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:25:00.216674\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:25:00.253002\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:25:01.377420\n",
      "Started at  2019-01-17 16:25:01.382584\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:25:01.384299\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:25:01.412145\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:25:43.908153\n",
      "[[()], [(' disaster_accident', ' environment', ' health', ' hiv', ' medicine', ' population', ' technology_internet', ' world bank number', 'disaster_accident', 'health_medical_pharma', 'hospitality_recreation', 'law_crime')], [(' health',)], [(' health',)]]\n",
      "Case index  10\n",
      "Started at  2019-01-17 16:25:44.050391\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:25:44.051477\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:25:44.083112\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:25:46.079848\n",
      "Started at  2019-01-17 16:25:46.093591\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:25:46.094444\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:25:46.118887\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:26:25.106616\n",
      "Started at  2019-01-17 16:26:25.234579\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:26:25.236315\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:26:25.267626\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:26:26.465480\n",
      "Started at  2019-01-17 16:26:26.470270\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:26:26.471833\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:26:26.504840\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:27:09.315790\n",
      "[[()], [(' disaster_accident', ' economics', ' environment', ' health', ' health_medical_pharma', ' human interest', ' international development', ' medicine', ' money', ' real gross domestic product', ' social issues', ' tax', ' technology_internet', 'disaster_accident', 'health_medical_pharma')], [()], [()]]\n",
      "Case index  11\n",
      "Started at  2019-01-17 16:27:09.428638\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:27:09.429654\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:27:09.462126\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:27:11.209528\n",
      "Started at  2019-01-17 16:27:11.225954\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:27:11.226969\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:27:11.260861\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:27:50.125322\n",
      "Started at  2019-01-17 16:27:50.219760\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:27:50.221375\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:27:50.256850\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:27:51.199247\n",
      "Started at  2019-01-17 16:27:51.204263\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:27:51.205226\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:27:51.244629\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:28:33.041430\n",
      "[[()], [(' disaster_accident', ' economics', ' energy development', ' energy economics', ' environment', ' fuel', ' government', ' health', ' health_medical_pharma', ' hiv', ' human interest', ' international development', ' medicine', ' population', ' poverty', ' poverty threshold', ' real gross domestic product', ' tax', ' technology_internet', ' world bank population', 'disaster_accident', 'health_medical_pharma', 'hospitality_recreation', 'law_crime', 'macroeconomics', 'social issues')], [(' poverty', ' poverty in india', ' poverty threshold', 'social issues')], [(' poverty', ' poverty threshold', 'social issues')]]\n",
      "Case index  12\n",
      "Started at  2019-01-17 16:28:33.154170\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:28:33.155099\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:28:33.188666\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:28:35.063053\n",
      "Started at  2019-01-17 16:28:35.077372\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:28:35.078841\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:28:35.105046\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:29:13.929231\n",
      "Started at  2019-01-17 16:29:14.060638\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:29:14.062362\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:29:14.088808\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:29:15.297401\n",
      "Started at  2019-01-17 16:29:15.305264\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:29:15.306926\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:29:15.335259\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:29:58.438095\n",
      "[[()], [(' disaster_accident', ' economics', ' environment', ' health', ' hospitality_recreation', ' money', ' politics', ' rtt', ' technology_internet', ' transport', 'disaster_accident', 'health_medical_pharma')], [(' transport',)], [(' transport',)]]\n",
      "Case index  13\n",
      "Started at  2019-01-17 16:29:58.558161\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:29:58.559125\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:29:58.578784\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:30:00.545804\n",
      "Started at  2019-01-17 16:30:00.560870\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:30:00.562439\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:30:00.588757\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:30:39.682249\n",
      "Started at  2019-01-17 16:30:39.801667\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:30:39.802714\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:30:39.828462\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2019-01-17 16:30:40.899153\n",
      "Started at  2019-01-17 16:30:40.903254\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:30:40.904073\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:30:40.927549\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:31:24.297928\n",
      "[[()], [(' disaster_accident', ' environment', ' freight transport', ' law_crime', ' technology_internet', ' transport', ' world bank number', 'disaster_accident', 'freight transport', 'health_medical_pharma', 'law_crime')], [()], [()]]\n",
      "Case index  14\n",
      "Started at  2019-01-17 16:31:24.427631\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:31:24.429496\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:31:24.474669\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:31:26.617496\n",
      "Started at  2019-01-17 16:31:26.636135\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:31:26.637434\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:31:26.681936\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:32:05.915530\n",
      "Started at  2019-01-17 16:32:06.016154\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:32:06.017396\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:32:06.058592\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:32:07.161655\n",
      "Started at  2019-01-17 16:32:07.167354\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:32:07.168632\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:32:07.213310\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:32:48.967989\n",
      "[[()], [(' clinical medicine', ' cpia', ' de facto', ' demographic economics', ' demography', ' disaster_accident', ' environment', ' environmental social science', ' financial economics', ' government', ' health_medical_pharma', ' hiv', ' law_crime', ' medicine', ' politics', ' population', ' religion_belief', ' rtt', ' social issues', ' taxation in the united states', ' technology_internet', ' tertiary education', ' war_conflict', ' world bank number', ' world bank population', 'health_medical_pharma', 'labor', 'law_crime', 'social issues', 'technology_internet')], [(' de facto', ' world bank population', 'social issues')], [(' de facto', ' world bank population', 'social issues')]]\n",
      "Case index  15\n",
      "Started at  2019-01-17 16:32:49.088144\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:32:49.089623\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:32:49.108437\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:32:50.854987\n",
      "Started at  2019-01-17 16:32:50.867592\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:32:50.868373\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:32:50.887405\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:33:29.982702\n",
      "Started at  2019-01-17 16:33:30.100698\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:33:30.101765\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:33:30.123310\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:33:31.281861\n",
      "Started at  2019-01-17 16:33:31.286322\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:33:31.287229\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:33:31.307588\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:34:14.860950\n",
      "[[()], [(' cpia', ' disaster_accident', ' economics', ' employee benefits', ' environment', ' expenditure', ' government', ' government final consumption expenditure', ' health', ' health_medical_pharma', ' household final consumption expenditure', ' human behavior', ' labor', ' medicine', ' national accounts', ' public health', ' rtt', ' social programs', ' tax', ' technology_internet', ' world bank cpia', ' world bank number', 'environment', 'law_crime', 'technology_internet')], [(' labor', ' money', ' national accounts', ' social issues', 'health_medical_pharma')], [(' labor', ' national accounts')]]\n",
      "Case index  16\n",
      "Started at  2019-01-17 16:34:15.000921\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:34:15.002812\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:34:15.020972\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:34:17.021367\n",
      "Started at  2019-01-17 16:34:17.036935\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:34:17.038296\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:34:17.053362\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:34:56.004955\n",
      "Started at  2019-01-17 16:34:56.114768\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:34:56.116071\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:34:56.133341\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:34:57.085105\n",
      "Started at  2019-01-17 16:34:57.089735\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:34:57.090453\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:34:57.103149\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:35:39.330209\n",
      "[[()], [(' disaster_accident', ' employee benefits', ' environment', ' expense', ' government', ' government final consumption expenditure', ' gross domestic product', ' health_medical_pharma', ' law_crime', ' social issues', ' tax', ' taxation in the united states', ' technology_internet', ' world bank adjusted', ' world bank cpia', ' world bank number', 'education', 'environment')], [(' consumption', ' expenditure', ' government final consumption expenditure', ' national accounts')], [(' government final consumption expenditure',)]]\n",
      "Case index  17\n",
      "Started at  2019-01-17 16:35:39.453857\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:35:39.455123\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:35:39.513275\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:35:41.634717\n",
      "Started at  2019-01-17 16:35:41.649979\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:35:41.652298\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:35:41.709413\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:36:21.341794\n",
      "Started at  2019-01-17 16:36:21.447763\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:36:21.449227\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:36:21.503146\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:36:22.634292\n",
      "Started at  2019-01-17 16:36:22.639133\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:36:22.640279\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:36:22.700731\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:37:05.436079\n",
      "[[()], [(' ageing', ' demographic economics', ' demography', ' disaster_accident', ' energy development', ' environment', ' expense', ' government', ' health_medical_pharma', ' hiv', ' human interest', ' infant', ' medicine', ' politics', ' population', ' religion_belief', ' rtt', ' tax', ' taxation in the united states', ' technology_internet', ' tertiary education', ' world bank population', 'disaster_accident', 'health_medical_pharma', 'macroeconomics')], [(' environment', ' hollowayville', ' il micropolitan statistical area', ' illinois', ' ottawa–peru', ' world bank population', 'social issues')], [(' environment', ' world bank population')]]\n",
      "Case index  18\n",
      "Started at  2019-01-17 16:37:05.551408\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:37:05.552248\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:37:05.594559\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:37:07.353495\n",
      "Started at  2019-01-17 16:37:07.370382\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:37:07.371422\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:37:07.415201\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:37:46.326025\n",
      "Started at  2019-01-17 16:37:46.434773\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:37:46.437738\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:37:46.480041\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:37:47.397801\n",
      "Started at  2019-01-17 16:37:47.401903\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:37:47.403241\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:37:47.450097\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:38:29.171600\n",
      "[[()], [(' ageing', ' demography', ' disaster_accident', ' environment', ' food and drink', ' government', ' health', ' hiv', ' hospitality_recreation', ' information and communications technology', ' medicine', ' public health', ' technology_internet', ' urban planning', ' world bank cpia', ' world bank number', ' world bank population', 'disaster_accident', 'health_medical_pharma', 'hospitality_recreation', 'law_crime')], [(' environment', ' hollowayville', ' illinois', ' world bank population', 'social issues')], [(' environment', ' world bank population')]]\n",
      "Case index  19\n",
      "Started at  2019-01-17 16:38:29.292485\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:38:29.294115\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:38:29.309617\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:38:31.405109\n",
      "Started at  2019-01-17 16:38:31.419822\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:38:31.421309\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:38:31.435891\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2019-01-17 16:39:10.653731\n",
      "Started at  2019-01-17 16:39:10.765487\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:39:10.766881\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:39:10.782511\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:39:11.681170\n",
      "Started at  2019-01-17 16:39:11.685163\n",
      "Tokenisation is running.\n",
      "Done at  2019-01-17 16:39:11.686338\n",
      "Vectorisation is running.\n",
      "Done at  2019-01-17 16:39:11.710009\n",
      "Creating labels.\n",
      "Done at  2019-01-17 16:39:54.096568\n",
      "[[('social issues',)], [(' ageing', ' de facto', ' demography', ' disaster_accident', ' environment', ' environmental social science', ' government', ' gross domestic product', ' law_crime', ' medicine', ' politics', ' population', ' technology_internet', ' urban planning', ' world bank cpia', ' world bank population', 'health_medical_pharma', 'macroeconomics', 'social issues')], [(' environment', ' world bank population', 'social issues')], [(' environment', ' world bank population', 'social issues')]]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for i, case in enumerate(testcases):\n",
    "    print('Case index ', i)\n",
    "    inner_list = []\n",
    "    inner_list.append(labelDataRFC(vectorizeStringList(tokenizeString(case[1], case[0]))))\n",
    "    inner_list.append(labelDataOVRRFC(vectorizeStringList(tokenizeString(case[1], case[0]))))\n",
    "    inner_list.append(labelDataOVRkNN(vectorizeStringList(tokenizeString(case[1], case[0]))))\n",
    "    inner_list.append(labelDataVoting(vectorizeStringList(tokenizeString(case[1], case[0]))))\n",
    "    print(inner_list)\n",
    "    labels.append(inner_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier ----- OvR RFC ----- OvR kNN ----- Voting Classifier\n",
      "==================================================================\n",
      "Case  0 :\n",
      "[()] - - [(' cpia', ' demography', ' disaster_accident', ' environment', ' expense', ' government', ' health', ' health_medical_pharma', ' hiv', ' human interest', ' infant', ' law_crime', ' medicine', ' population', ' rtt', ' technology_internet', ' world bank number', 'disaster_accident', 'health_medical_pharma', 'human interest', 'law_crime')] - - [(' demography', ' health')] - - [(' demography', ' health')] - - \n",
      "==================================================================\n",
      "Case  1 :\n",
      "[()] - - [(' cpia', ' environment', ' government', ' health', ' labor', ' law', ' law_crime', ' tax', 'disaster_accident')] - - [(' business', ' freight transport', ' international relations')] - - [()] - - \n",
      "==================================================================\n",
      "Case  2 :\n",
      "[()] - - [(' chemistry', ' climate change policy', ' climatology', ' disaster_accident', ' energy development', ' energy economics', ' environment', ' fossil fuel', ' fuel', ' fuels', ' government', ' greenhouse gas', ' greenhouse gases', ' health_medical_pharma', ' human interest', ' low-carbon economy', ' nature', ' technology_internet', ' universe', 'disaster_accident', 'environment')] - - [(' climate change policy', ' fuels', ' greenhouse gases', ' nature', ' universe', 'environment')] - - [(' climate change policy', ' fuels', ' greenhouse gases', ' nature', ' universe', 'environment')] - - \n",
      "==================================================================\n",
      "Case  3 :\n",
      "[()] - - [(' cpia', ' disaster_accident', ' energy development', ' energy economics', ' environment', ' government', ' greenhouse gases', ' health', ' nature', ' social issues', ' technology_internet', ' universe', ' world bank cpia', ' world bank number', 'environment', 'health_medical_pharma', 'law_crime', 'technology_internet')] - - [(' nature', 'environment')] - - [(' nature', 'environment')] - - \n",
      "==================================================================\n",
      "Case  4 :\n",
      "[()] - - [(' chemistry', ' cpia', ' debt-to-gdp ratio', ' disaster_accident', ' energy development', ' environment', ' food and drink', ' government', ' health_medical_pharma', ' hospitality_recreation', ' human geography', ' international development', ' international trade', ' labor', ' macroeconomics', ' nature', ' rtt', ' security', ' technology_internet', ' transport', ' world bank cpia', 'disaster_accident', 'health_medical_pharma', 'hospitality_recreation', 'macroeconomics', 'politics', 'technology_internet')] - - [(' macroeconomics',)] - - [(' macroeconomics',)] - - \n",
      "==================================================================\n",
      "Case  5 :\n",
      "[()] - - [(' cpia', ' disaster_accident', ' economics', ' energy development', ' environment', ' government', ' health', ' health_medical_pharma', ' hiv', ' medicine', ' national accounts', ' real gross domestic product', ' religion_belief', ' social issues', ' tax', ' technology_internet', ' universe', 'disaster_accident', 'international trade', 'law_crime', 'macroeconomics', 'technology_internet')] - - [()] - - [()] - - \n",
      "==================================================================\n",
      "Case  6 :\n",
      "[()] - - [(' disaster_accident', ' economics', ' environment', ' health_medical_pharma', ' human interest', ' population', ' real gross domestic product', ' social issues', ' technology_internet', ' world bank population', 'disaster_accident', 'law_crime', 'macroeconomics', 'social issues')] - - [()] - - [()] - - \n",
      "==================================================================\n",
      "Case  7 :\n",
      "[()] - - [(' cpia', ' disaster_accident', ' environment', ' expenditure', ' general government', ' government', ' government final consumption expenditure', ' gross domestic product', ' health', ' household final consumption expenditure', ' medicine', ' military budget', ' politics', ' social statistics', ' tax', ' technology_internet', ' united kingdom national accounts – the blue book', ' world bank adjusted', ' world bank cpia', ' world bank gross', ' world bank number', 'health_medical_pharma', 'law_crime', 'social issues', 'tax')] - - [(' expenditure', ' final consumption expenditure', ' government final consumption expenditure', ' household final consumption expenditure', ' money', ' national accounts', 'politics')] - - [(' expenditure', ' government final consumption expenditure', ' household final consumption expenditure')] - - \n",
      "==================================================================\n",
      "Case  8 :\n",
      "[()] - - [(' chemistry', ' cpia', ' demography', ' disaster_accident', ' economics', ' environment', ' human behavior', ' human interest', ' medicine', ' money', ' religion_belief', ' rtt', ' social issues', ' teacher', ' technology_internet', ' tertiary education', 'disaster_accident', 'education', 'health_medical_pharma', 'law_crime')] - - [(' education', ' teacher', 'education')] - - [(' teacher', 'education')] - - \n",
      "==================================================================\n",
      "Case  9 :\n",
      "[()] - - [(' disaster_accident', ' environment', ' health', ' hiv', ' medicine', ' population', ' technology_internet', ' world bank number', 'disaster_accident', 'health_medical_pharma', 'hospitality_recreation', 'law_crime')] - - [(' health',)] - - [(' health',)] - - \n",
      "==================================================================\n",
      "Case  10 :\n",
      "[()] - - [(' disaster_accident', ' economics', ' environment', ' health', ' health_medical_pharma', ' human interest', ' international development', ' medicine', ' money', ' real gross domestic product', ' social issues', ' tax', ' technology_internet', 'disaster_accident', 'health_medical_pharma')] - - [()] - - [()] - - \n",
      "==================================================================\n",
      "Case  11 :\n",
      "[()] - - [(' disaster_accident', ' economics', ' energy development', ' energy economics', ' environment', ' fuel', ' government', ' health', ' health_medical_pharma', ' hiv', ' human interest', ' international development', ' medicine', ' population', ' poverty', ' poverty threshold', ' real gross domestic product', ' tax', ' technology_internet', ' world bank population', 'disaster_accident', 'health_medical_pharma', 'hospitality_recreation', 'law_crime', 'macroeconomics', 'social issues')] - - [(' poverty', ' poverty in india', ' poverty threshold', 'social issues')] - - [(' poverty', ' poverty threshold', 'social issues')] - - \n",
      "==================================================================\n",
      "Case  12 :\n",
      "[()] - - [(' disaster_accident', ' economics', ' environment', ' health', ' hospitality_recreation', ' money', ' politics', ' rtt', ' technology_internet', ' transport', 'disaster_accident', 'health_medical_pharma')] - - [(' transport',)] - - [(' transport',)] - - \n",
      "==================================================================\n",
      "Case  13 :\n",
      "[()] - - [(' disaster_accident', ' environment', ' freight transport', ' law_crime', ' technology_internet', ' transport', ' world bank number', 'disaster_accident', 'freight transport', 'health_medical_pharma', 'law_crime')] - - [()] - - [()] - - \n",
      "==================================================================\n",
      "Case  14 :\n",
      "[()] - - [(' clinical medicine', ' cpia', ' de facto', ' demographic economics', ' demography', ' disaster_accident', ' environment', ' environmental social science', ' financial economics', ' government', ' health_medical_pharma', ' hiv', ' law_crime', ' medicine', ' politics', ' population', ' religion_belief', ' rtt', ' social issues', ' taxation in the united states', ' technology_internet', ' tertiary education', ' war_conflict', ' world bank number', ' world bank population', 'health_medical_pharma', 'labor', 'law_crime', 'social issues', 'technology_internet')] - - [(' de facto', ' world bank population', 'social issues')] - - [(' de facto', ' world bank population', 'social issues')] - - \n",
      "==================================================================\n",
      "Case  15 :\n",
      "[()] - - [(' cpia', ' disaster_accident', ' economics', ' employee benefits', ' environment', ' expenditure', ' government', ' government final consumption expenditure', ' health', ' health_medical_pharma', ' household final consumption expenditure', ' human behavior', ' labor', ' medicine', ' national accounts', ' public health', ' rtt', ' social programs', ' tax', ' technology_internet', ' world bank cpia', ' world bank number', 'environment', 'law_crime', 'technology_internet')] - - [(' labor', ' money', ' national accounts', ' social issues', 'health_medical_pharma')] - - [(' labor', ' national accounts')] - - \n",
      "==================================================================\n",
      "Case  16 :\n",
      "[()] - - [(' disaster_accident', ' employee benefits', ' environment', ' expense', ' government', ' government final consumption expenditure', ' gross domestic product', ' health_medical_pharma', ' law_crime', ' social issues', ' tax', ' taxation in the united states', ' technology_internet', ' world bank adjusted', ' world bank cpia', ' world bank number', 'education', 'environment')] - - [(' consumption', ' expenditure', ' government final consumption expenditure', ' national accounts')] - - [(' government final consumption expenditure',)] - - \n",
      "==================================================================\n",
      "Case  17 :\n",
      "[()] - - [(' ageing', ' demographic economics', ' demography', ' disaster_accident', ' energy development', ' environment', ' expense', ' government', ' health_medical_pharma', ' hiv', ' human interest', ' infant', ' medicine', ' politics', ' population', ' religion_belief', ' rtt', ' tax', ' taxation in the united states', ' technology_internet', ' tertiary education', ' world bank population', 'disaster_accident', 'health_medical_pharma', 'macroeconomics')] - - [(' environment', ' hollowayville', ' il micropolitan statistical area', ' illinois', ' ottawa–peru', ' world bank population', 'social issues')] - - [(' environment', ' world bank population')] - - \n",
      "==================================================================\n",
      "Case  18 :\n",
      "[()] - - [(' ageing', ' demography', ' disaster_accident', ' environment', ' food and drink', ' government', ' health', ' hiv', ' hospitality_recreation', ' information and communications technology', ' medicine', ' public health', ' technology_internet', ' urban planning', ' world bank cpia', ' world bank number', ' world bank population', 'disaster_accident', 'health_medical_pharma', 'hospitality_recreation', 'law_crime')] - - [(' environment', ' hollowayville', ' illinois', ' world bank population', 'social issues')] - - [(' environment', ' world bank population')] - - \n",
      "==================================================================\n",
      "Case  19 :\n",
      "[('social issues',)] - - [(' ageing', ' de facto', ' demography', ' disaster_accident', ' environment', ' environmental social science', ' government', ' gross domestic product', ' law_crime', ' medicine', ' politics', ' population', ' technology_internet', ' urban planning', ' world bank cpia', ' world bank population', 'health_medical_pharma', 'macroeconomics', 'social issues')] - - [(' environment', ' world bank population', 'social issues')] - - [(' environment', ' world bank population', 'social issues')] - - \n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "print('RandomForestClassifier ----- OvR RFC ----- OvR kNN ----- Voting Classifier\\n==================================================================')\n",
    "for i, line in enumerate(labels):\n",
    "    print('Case ', i, ':')\n",
    "    for elem in line:\n",
    "        print(elem, end=' - - ')\n",
    "    print('\\n==================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
