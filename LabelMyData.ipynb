{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2018-11-24 19:42:27\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import nltk\n",
    "import requests\n",
    "import _pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk import ngrams, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print('_______________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Def Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTxt(path):  \n",
    "    return open(path, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fillerwords = getTxt('../input/fillerwords.txt').split(',') + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeString(title, desc):\n",
    "    print('Started at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    print('Tokenisation is running.')\n",
    "    global list_fillerwords\n",
    "    string_to_clean = title + ' ' + desc\n",
    "    porterstemmer = PorterStemmer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    \n",
    "    list_token = nltk.word_tokenize(''.join([x for x in string_to_clean if not x.isdigit()]).replace('-',' ').replace('.','').replace(',','').replace('%','').replace(';',' ').replace('/', ' ').replace('(','').replace(')',''))\n",
    "    \n",
    "    for word in list_fillerwords:\n",
    "        while (word in list_token):\n",
    "            list_token.remove(word)\n",
    "            \n",
    "    for i, word in enumerate(list_token):\n",
    "        list_token[i] = list_token[i].lower()\n",
    "        lemmatizer.lemmatize(porterstemmer.stem(list_token[i]))\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return list_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for summing up single vectors (=words) in a vectorlist\n",
    "def sumVect(list_vect):\n",
    "    try:\n",
    "        for i, elem in enumerate(list_vect):\n",
    "            if not elem:\n",
    "                del list_vect[i]\n",
    "        \n",
    "        int_len_vect = len(list_vect[0])\n",
    "        list_vect_sum = [0] * int_len_vect\n",
    "        for vect in list_vect:\n",
    "            for i, dim in enumerate(vect):\n",
    "                list_vect_sum[i] += float(dim)\n",
    "        return(list_vect_sum)\n",
    "    except Exception as e:\n",
    "        print(list_vect)\n",
    "        print(i)\n",
    "        print(list_vect_sum)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeStringList(list_string):\n",
    "    print('Vectorisation is running.')\n",
    "    adress = 'http://word2vec.ai.wu.ac.at/googlenews/model?word='\n",
    "    feat_words = []\n",
    "    \n",
    "    for str_elem in list_string:\n",
    "        word = str_elem.strip() \n",
    "        try:\n",
    "            feat_words.append([float(x) for x in requests.get((adress+word)).text.replace(' ','').replace('[','').replace(']','').split(',')])\n",
    "        except:\n",
    "            try:\n",
    "                feat_words.append([float(x) for x in requests.get((adress+word.title())).text.replace(' ','').replace('[','').replace(']','').split(',')])\n",
    "            except Exception as e:\n",
    "                feat_words.append([])\n",
    "                           \n",
    "    if feat_words:\n",
    "        list_return = sumVect(feat_words)\n",
    "        \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelData(vect):\n",
    "    print('Creating labels.')\n",
    "        \n",
    "    with open('my_dumped_classifier.pkl', 'rb') as fid:\n",
    "        rf_load = _pickle.load(fid)\n",
    "    with open('my_dumped_binarizer.pkl', 'rb') as fid:\n",
    "        bin_load = _pickle.load(fid)\n",
    "    \n",
    "    np_in = [vect]\n",
    "    X = np.array(np_in)\n",
    "    pred_rf = rf_load.predict(X)\n",
    "    pred_label = bin_load.inverse_transform(pred_rf)\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2018-11-24 19:42:32.495273\n",
      "Tokenisation is running.\n",
      "Done at  2018-11-24 19:42:32.498277\n",
      "Vectorisation is running.\n",
      "Done at  2018-11-24 19:42:34.312934\n",
      "Creating labels.\n",
      "Done at  2018-11-24 19:42:35.311849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' business',\n",
       "  ' female labor force in the muslim world',\n",
       "  ' international labour organization',\n",
       "  ' structure',\n",
       "  ' unemployment',\n",
       "  ' united nations',\n",
       "  ' united nations development group',\n",
       "  ' workforce',\n",
       "  'social issues')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Labor force participation rate, female (% of female population ages 15+) (modeled ILO estimate), countries grouped by income levels'\n",
    "describtion = 'Labor force participation rate is the proportion of the population ages 15 and older that is economically active: all people who supply labor for the production of goods and services during a specified period.'\n",
    "labelData(vectorizeStringList(tokenizeString(title, describtion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
