{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2018-12-05 02:10:46\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import nltk\n",
    "import requests\n",
    "import _pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk import ngrams, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "print(datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print('_______________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Def Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTxt(path):  \n",
    "    return open(path, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fillerwords = getTxt('../input/fillerwords.txt').split(',') + stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeString(title, desc):\n",
    "    print('Started at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    print('Tokenisation is running.')\n",
    "    global list_fillerwords\n",
    "    string_to_clean = title + ' ' + desc\n",
    "    porterstemmer = PorterStemmer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    \n",
    "    list_token = nltk.word_tokenize(''.join([x for x in string_to_clean if not x.isdigit()]).replace('-',' ').replace('.','').replace(',','').replace('%','').replace(';',' ').replace('/', ' ').replace('(','').replace(')',''))\n",
    "    \n",
    "    for word in list_fillerwords:\n",
    "        while (word in list_token):\n",
    "            list_token.remove(word)\n",
    "            \n",
    "    for i, word in enumerate(list_token):\n",
    "        list_token[i] = list_token[i].lower()\n",
    "        lemmatizer.lemmatize(porterstemmer.stem(list_token[i]))\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return list_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for summing up single vectors (=words) in a vectorlist\n",
    "def sumVect(list_vect):\n",
    "    try:\n",
    "        for i, elem in enumerate(list_vect):\n",
    "            if not elem:\n",
    "                del list_vect[i]\n",
    "        \n",
    "        int_len_vect = len(list_vect[0])\n",
    "        list_vect_sum = [0] * int_len_vect\n",
    "        for vect in list_vect:\n",
    "            for i, dim in enumerate(vect):\n",
    "                list_vect_sum[i] += float(dim)\n",
    "        return(list_vect_sum)\n",
    "    except Exception as e:\n",
    "        print(list_vect)\n",
    "        print(i)\n",
    "        print(list_vect_sum)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeStringList(list_string):\n",
    "    print('Vectorisation is running.')\n",
    "    adress = 'http://word2vec.ai.wu.ac.at/googlenews/model?word='\n",
    "    feat_words = []\n",
    "    \n",
    "    for str_elem in list_string:\n",
    "        word = str_elem.strip() \n",
    "        try:\n",
    "            feat_words.append([float(x) for x in requests.get((adress+word)).text.replace(' ','').replace('[','').replace(']','').split(',')])\n",
    "        except:\n",
    "            try:\n",
    "                feat_words.append([float(x) for x in requests.get((adress+word.title())).text.replace(' ','').replace('[','').replace(']','').split(',')])\n",
    "            except Exception as e:\n",
    "                feat_words.append([])\n",
    "                           \n",
    "    if feat_words:\n",
    "        list_return = sumVect(feat_words)\n",
    "        \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return list_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelDataRFC(vect):\n",
    "    print('Creating labels.')\n",
    "        \n",
    "    with open('dumped_randomforestclassifier.pkl', 'rb') as fid:\n",
    "        rf_load = _pickle.load(fid)\n",
    "    with open('dumped_binarizer.pkl', 'rb') as fid:\n",
    "        bin_load = _pickle.load(fid)\n",
    "    \n",
    "    np_in = [vect]\n",
    "    X = np.array(np_in)\n",
    "    pred_rf = rf_load.predict(X)\n",
    "    pred_label = bin_load.inverse_transform(pred_rf)\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelDataOVRkNN(vect):\n",
    "    print('Creating labels.')\n",
    "        \n",
    "    with open('dumped_ovrknn.pkl', 'rb') as fid:\n",
    "        rf_load = _pickle.load(fid)\n",
    "    with open('dumped_binarizer.pkl', 'rb') as fid:\n",
    "        bin_load = _pickle.load(fid)\n",
    "    \n",
    "    np_in = [vect]\n",
    "    X = np.array(np_in)\n",
    "    pred_rf = rf_load.predict(X)\n",
    "    pred_label = bin_load.inverse_transform(pred_rf)\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelDataOVRRFC(vect):\n",
    "    print('Creating labels.')\n",
    "        \n",
    "    with open('dumped_ovrrfc.pkl', 'rb') as fid:\n",
    "        rf_load = _pickle.load(fid)\n",
    "    with open('dumped_binarizer.pkl', 'rb') as fid:\n",
    "        bin_load = _pickle.load(fid)\n",
    "    \n",
    "    np_in = [vect]\n",
    "    X = np.array(np_in)\n",
    "    pred_rf = rf_load.predict(X)\n",
    "    pred_label = bin_load.inverse_transform(pred_rf)\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelDataVoting(vect):\n",
    "    print('Creating labels.')\n",
    "        \n",
    "    with open('dumped_randomforestclassifier.pkl', 'rb') as fid:\n",
    "        rf_load = _pickle.load(fid)\n",
    "    with open('dumped_ovrrfc.pkl', 'rb') as fid:\n",
    "        ovrrf_load = _pickle.load(fid)\n",
    "    with open('dumped_ovrknn.pkl', 'rb') as fid:\n",
    "        ovrknn_load = _pickle.load(fid)\n",
    "    with open('dumped_binarizer.pkl', 'rb') as fid:\n",
    "        bin_load = _pickle.load(fid)\n",
    "    \n",
    "    np_in = [vect]\n",
    "    X = np.array(np_in)\n",
    "    pred_rf = rf_load.predict(X)\n",
    "    pred_ovrrf = ovrrf_load.predict(X)\n",
    "    pred_ovrknn = ovrknn_load.predict(X)\n",
    "    \n",
    "    pred_label = ((pred_rf+pred_ovrrf+pred_ovrknn)/3)\n",
    "    for i, label in enumerate(pred_label[0]):\n",
    "        if label > 0.5:\n",
    "            pred_label[0][i] = 1\n",
    "        else:\n",
    "            pred_label[0][i] = 0\n",
    "        \n",
    "        \n",
    "    pred_out = bin_load.inverse_transform(pred_label)\n",
    "    \n",
    "    print('Done at ' , datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    return pred_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = 'Labor force participation rate, female (% of female population ages 15+) (modeled ILO estimate), countries grouped by income levels'\n",
    "# describtion = 'Labor force participation rate is the proportion of the population ages 15 and older that is economically active: all people who supply labor for the production of goods and services during a specified period.'\n",
    "title = 'CO2 emissions (metric tons per capita)'\n",
    "describtion = 'Carbon dioxide emissions are those stemming from the burning of fossil fuels and the manufacture of cement. They include carbon dioxide produced during consumption of solid, liquid, and gas fuels and gas flaring. Government reaction taxes issue '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2018-12-05 02:10:46.682182\n",
      "Tokenisation is running.\n",
      "Done at  2018-12-05 02:10:48.562149\n",
      "Vectorisation is running.\n",
      "Done at  2018-12-05 02:10:57.648889\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2018-12-05 02:10:58.756923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' chemistry', ' universe', 'environment')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDataRFC(vectorizeStringList(tokenizeString(title, describtion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2018-12-05 02:11:02.717100\n",
      "Tokenisation is running.\n",
      "Done at  2018-12-05 02:11:02.720093\n",
      "Vectorisation is running.\n",
      "Done at  2018-12-05 02:11:14.763058\n",
      "Creating labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator _ConstantPredictor from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at  2018-12-05 02:11:28.287573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' chemistry', ' universe', 'environment')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelDataOVRRFC(vectorizeStringList(tokenizeString(title, describtion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDataVoting(vectorizeStringList(tokenizeString(title, describtion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2018-12-05 02:11:39.851882\n",
      "Tokenisation is running.\n",
      "Done at  2018-12-05 02:11:39.853861\n",
      "Vectorisation is running.\n"
     ]
    }
   ],
   "source": [
    "labelDataOVRkNN(vectorizeStringList(tokenizeString(title, describtion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
